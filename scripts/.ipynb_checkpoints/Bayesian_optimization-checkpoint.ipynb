{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwpMaCm0gzcJ",
        "outputId": "c5b76491-be22-416a-e274-1dfc0f1502ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=5a0fc32a0b83b98cd5b61abd1354ca4433025d1af4629ac953f1012698ae1fba\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC"
      ],
      "metadata": {
        "id": "NnIKfQ_Mg3oE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from bayes_opt.util import Colours\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from bayes_opt.logger import JSONLogger\n",
        "from bayes_opt.event import Events"
      ],
      "metadata": {
        "id": "O6sIhI80hD1Y"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('stocks_quarterly.csv')\n",
        "\n",
        "df2 = pd.read_csv('new_data_test.csv')\n",
        "\n",
        "df = pd.concat([df,df2])"
      ],
      "metadata": {
        "id": "RCNALVzohca6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = df.isnull().mean().sort_values(ascending = False).head(45).index\n",
        "\n",
        "cols_to_drop = list(cols_to_drop) + ['fiscalDateEnding','reportedDate','price','nasd_price',\\\n",
        "                                     'next_year_date','next_year_price','nasd_ny_price','symbol',\\\n",
        "                                     'Nasdaq_Performance', 'Stock_Performance']\n",
        "\n",
        "df.drop(columns = cols_to_drop, inplace = True)"
      ],
      "metadata": {
        "id": "NvVCIcF1h3L4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "PX3PIW0YiBWb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = 'Label')\n",
        "y = df.Label"
      ],
      "metadata": {
        "id": "N54FCgMDiFP4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipline = make_pipeline(SimpleImputer(strategy='median'))"
      ],
      "metadata": {
        "id": "vrH7ldUaiID7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pipline.fit_transform(X)"
      ],
      "metadata": {
        "id": "L0LYie1miJC-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfc_cv(n_estimators, min_samples_split, max_features,max_depth,min_samples_leaf, data, targets):\n",
        "    \"\"\"Random Forest cross validation.\n",
        "    This function will instantiate a random forest classifier with parameters\n",
        "    n_estimators, min_samples_split, and max_features. Combined with data and\n",
        "    targets this will in turn be used to perform cross validation. The result\n",
        "    of cross validation is returned.\n",
        "    Our goal is to find combinations of n_estimators, min_samples_split, and\n",
        "    max_features that minimzes the log loss.\n",
        "    \"\"\"\n",
        "\n",
        "    estimator = RFC(\n",
        "        n_estimators=n_estimators,\n",
        "        min_samples_split=min_samples_split,\n",
        "        max_features=max_features,\n",
        "        max_depth = max_depth,\n",
        "        min_samples_leaf = min_samples_leaf,\n",
        "        random_state=2\n",
        "    )\n",
        "    cval = cross_val_score(estimator, data, targets,\n",
        "                           scoring='accuracy', cv=4)\n",
        "    return cval.mean()"
      ],
      "metadata": {
        "id": "kADF9XmKhIQm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_rfc(data, targets):\n",
        "    \"\"\"Apply Bayesian Optimization to Random Forest parameters.\"\"\"\n",
        "    def rfc_crossval(n_estimators, min_samples_split, max_features,max_depth,min_samples_leaf):\n",
        "        \"\"\"Wrapper of RandomForest cross validation.\n",
        "        Notice how we ensure n_estimators and min_samples_split are casted\n",
        "        to integer before we pass them along. Moreover, to avoid max_features\n",
        "        taking values outside the (0, 1) range, we also ensure it is capped\n",
        "        accordingly.\n",
        "        \"\"\"\n",
        "        return rfc_cv(\n",
        "            n_estimators=int(n_estimators),\n",
        "            min_samples_split=int(min_samples_split),\n",
        "            max_features=max(min(max_features, 0.99), 1e-3),\n",
        "            max_depth = int(max_depth),\n",
        "            min_samples_leaf = int(min_samples_leaf),\n",
        "            data=X,\n",
        "            targets=y,\n",
        "        )\n",
        "\n",
        "    optimizer = BayesianOptimization(\n",
        "        f=rfc_crossval,\n",
        "        pbounds={\n",
        "            \"n_estimators\": (10, 400),\n",
        "            \"min_samples_split\": (1, 25),\n",
        "            \"max_features\": (0.1, 0.99),\n",
        "            'max_depth' : (3,200),\n",
        "            'min_samples_leaf' : (2,10)\n",
        "        },\n",
        "        random_state=1234,\n",
        "        verbose=2\n",
        "    )\n",
        "    optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
        "    optimizer.maximize(init_points = 30, n_iter=400)\n",
        "\n",
        "    print(\"Final result:\", optimizer.max)"
      ],
      "metadata": {
        "id": "j8NFwFpxhaXS"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimize_rfc(X, y)"
      ],
      "metadata": {
        "id": "9lL8IYnEjm9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = JSONLogger(path=\"./logs.json\")\n"
      ],
      "metadata": {
        "id": "Mza72DAGju7G"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}