{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "83c68e22-64b8-4347-ba86-b09e0b479dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f718272e-6921-4021-8d57-3171d2fa4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stocks_quarterly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1c4d9006-a61b-4fc4-9c13-d0eed6643148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiscalDateEnding</th>\n",
       "      <th>grossProfit</th>\n",
       "      <th>totalRevenue</th>\n",
       "      <th>costOfRevenue</th>\n",
       "      <th>costofGoodsAndServicesSold</th>\n",
       "      <th>operatingIncome</th>\n",
       "      <th>sellingGeneralAndAdministrative</th>\n",
       "      <th>researchAndDevelopment</th>\n",
       "      <th>operatingExpenses</th>\n",
       "      <th>investmentIncomeNet</th>\n",
       "      <th>...</th>\n",
       "      <th>surprisePercentage</th>\n",
       "      <th>price</th>\n",
       "      <th>nasd_price</th>\n",
       "      <th>next_year_date</th>\n",
       "      <th>next_year_price</th>\n",
       "      <th>nasd_ny_price</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Nasdaq_Performance</th>\n",
       "      <th>Stock_Performance</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>4.027000e+09</td>\n",
       "      <td>4.027000e+09</td>\n",
       "      <td>4.485000e+09</td>\n",
       "      <td>1.240000e+09</td>\n",
       "      <td>-2.515000e+09</td>\n",
       "      <td>1.860000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.127000e+09</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3380</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>13337.160156</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>15.640000</td>\n",
       "      <td>13770.570313</td>\n",
       "      <td>AAL</td>\n",
       "      <td>3.249643</td>\n",
       "      <td>-13.591160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>-2.310000e+09</td>\n",
       "      <td>2.833000e+09</td>\n",
       "      <td>5.143000e+09</td>\n",
       "      <td>1.156000e+09</td>\n",
       "      <td>-2.871000e+09</td>\n",
       "      <td>7.000000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.941000e+09</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7309</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>11506.009766</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>15090.200195</td>\n",
       "      <td>AAL</td>\n",
       "      <td>31.150594</td>\n",
       "      <td>45.627378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>-2.601000e+09</td>\n",
       "      <td>1.368000e+09</td>\n",
       "      <td>3.969000e+09</td>\n",
       "      <td>8.660000e+08</td>\n",
       "      <td>-2.486000e+09</td>\n",
       "      <td>4.300000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.133000e+09</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>11.770000</td>\n",
       "      <td>10461.419922</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>14836.990234</td>\n",
       "      <td>AAL</td>\n",
       "      <td>41.825778</td>\n",
       "      <td>80.118946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1.241000e+09</td>\n",
       "      <td>8.258000e+09</td>\n",
       "      <td>7.017000e+09</td>\n",
       "      <td>2.197000e+09</td>\n",
       "      <td>-2.549000e+09</td>\n",
       "      <td>3.050000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.857000e+09</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.5218</td>\n",
       "      <td>12.010000</td>\n",
       "      <td>8889.549805</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>21.719999</td>\n",
       "      <td>13962.679688</td>\n",
       "      <td>AAL</td>\n",
       "      <td>57.068468</td>\n",
       "      <td>80.849283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1.118900e+10</td>\n",
       "      <td>1.131300e+10</td>\n",
       "      <td>1.240000e+08</td>\n",
       "      <td>2.633000e+09</td>\n",
       "      <td>7.290000e+08</td>\n",
       "      <td>5.030000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.240000e+08</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5104</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>9402.480469</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>15.820000</td>\n",
       "      <td>13543.059570</td>\n",
       "      <td>AAL</td>\n",
       "      <td>44.037093</td>\n",
       "      <td>-45.069444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>4.329000e+09</td>\n",
       "      <td>1.162700e+10</td>\n",
       "      <td>7.298000e+09</td>\n",
       "      <td>2.854000e+09</td>\n",
       "      <td>8.080000e+08</td>\n",
       "      <td>4.240000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.508000e+09</td>\n",
       "      <td>34000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>29.410000</td>\n",
       "      <td>8185.799805</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>11548.280273</td>\n",
       "      <td>AAL</td>\n",
       "      <td>41.076994</td>\n",
       "      <td>-57.157428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>4.615000e+09</td>\n",
       "      <td>1.168500e+10</td>\n",
       "      <td>7.070000e+09</td>\n",
       "      <td>2.864000e+09</td>\n",
       "      <td>1.153000e+09</td>\n",
       "      <td>4.010000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.277000e+09</td>\n",
       "      <td>35000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7726</td>\n",
       "      <td>31.670000</td>\n",
       "      <td>8238.540039</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>11.390000</td>\n",
       "      <td>10363.179688</td>\n",
       "      <td>AAL</td>\n",
       "      <td>25.789031</td>\n",
       "      <td>-64.035364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.071100e+10</td>\n",
       "      <td>1.093800e+10</td>\n",
       "      <td>2.270000e+08</td>\n",
       "      <td>2.748000e+09</td>\n",
       "      <td>5.710000e+08</td>\n",
       "      <td>4.720000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.270000e+08</td>\n",
       "      <td>34000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>33.660000</td>\n",
       "      <td>7073.459961</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>27.639999</td>\n",
       "      <td>9314.910156</td>\n",
       "      <td>AAL</td>\n",
       "      <td>31.688173</td>\n",
       "      <td>-17.884731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>4.077000e+09</td>\n",
       "      <td>1.129400e+10</td>\n",
       "      <td>7.217000e+09</td>\n",
       "      <td>3.043000e+09</td>\n",
       "      <td>6.850000e+08</td>\n",
       "      <td>3.950000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341000e+09</td>\n",
       "      <td>29000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>32.369999</td>\n",
       "      <td>7318.339844</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>30.860001</td>\n",
       "      <td>8243.120117</td>\n",
       "      <td>AAL</td>\n",
       "      <td>12.636476</td>\n",
       "      <td>-4.664808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>4.369000e+09</td>\n",
       "      <td>1.137700e+10</td>\n",
       "      <td>7.008000e+09</td>\n",
       "      <td>2.898000e+09</td>\n",
       "      <td>1.004000e+09</td>\n",
       "      <td>3.478000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.441000e+09</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4706</td>\n",
       "      <td>40.020000</td>\n",
       "      <td>7852.180176</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>31.240000</td>\n",
       "      <td>8330.209961</td>\n",
       "      <td>AAL</td>\n",
       "      <td>6.087861</td>\n",
       "      <td>-21.939032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>3.648000e+09</td>\n",
       "      <td>1.013600e+10</td>\n",
       "      <td>6.488000e+09</td>\n",
       "      <td>2.529000e+09</td>\n",
       "      <td>3.960000e+08</td>\n",
       "      <td>3.373000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.220000e+09</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6041</td>\n",
       "      <td>42.369999</td>\n",
       "      <td>7118.680176</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>33.060001</td>\n",
       "      <td>8146.399902</td>\n",
       "      <td>AAL</td>\n",
       "      <td>14.436942</td>\n",
       "      <td>-21.973089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1.046100e+10</td>\n",
       "      <td>1.060000e+10</td>\n",
       "      <td>1.390000e+08</td>\n",
       "      <td>2.395000e+09</td>\n",
       "      <td>6.380000e+08</td>\n",
       "      <td>6.175000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390000e+08</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2833</td>\n",
       "      <td>53.049999</td>\n",
       "      <td>7411.160156</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>34.980000</td>\n",
       "      <td>7164.859863</td>\n",
       "      <td>AAL</td>\n",
       "      <td>-3.323370</td>\n",
       "      <td>-34.062205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>4.315000e+09</td>\n",
       "      <td>1.061200e+10</td>\n",
       "      <td>6.297000e+09</td>\n",
       "      <td>2.345000e+09</td>\n",
       "      <td>1.256000e+09</td>\n",
       "      <td>3.395000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.172000e+09</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5737</td>\n",
       "      <td>48.610001</td>\n",
       "      <td>6556.770020</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>32.459999</td>\n",
       "      <td>7167.209961</td>\n",
       "      <td>AAL</td>\n",
       "      <td>9.310071</td>\n",
       "      <td>-33.223619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3.556000e+09</td>\n",
       "      <td>9.367000e+09</td>\n",
       "      <td>5.811000e+09</td>\n",
       "      <td>2.137000e+09</td>\n",
       "      <td>7.370000e+08</td>\n",
       "      <td>3.143000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.828000e+09</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5688</td>\n",
       "      <td>43.980000</td>\n",
       "      <td>6048.939941</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>43.400002</td>\n",
       "      <td>7119.799805</td>\n",
       "      <td>AAL</td>\n",
       "      <td>17.703265</td>\n",
       "      <td>-1.318777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>-1.216900e+07</td>\n",
       "      <td>4.626900e+07</td>\n",
       "      <td>5.843800e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.522100e+07</td>\n",
       "      <td>1.160000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.160000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>12888.280273</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>15644.969727</td>\n",
       "      <td>AAME</td>\n",
       "      <td>21.389118</td>\n",
       "      <td>18.932044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>-4.415000e+06</td>\n",
       "      <td>4.973700e+07</td>\n",
       "      <td>5.415200e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.527000e+06</td>\n",
       "      <td>4.080000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.080000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11167.509766</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>14448.580078</td>\n",
       "      <td>AAME</td>\n",
       "      <td>29.380501</td>\n",
       "      <td>107.500005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>-2.792200e+07</td>\n",
       "      <td>3.941000e+07</td>\n",
       "      <td>6.733200e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.122700e+07</td>\n",
       "      <td>3.530000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.530000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>10058.769531</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>14503.950195</td>\n",
       "      <td>AAME</td>\n",
       "      <td>44.192092</td>\n",
       "      <td>160.240979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-5.366300e+07</td>\n",
       "      <td>5.228900e+07</td>\n",
       "      <td>1.059520e+08</td>\n",
       "      <td>6.713900e+07</td>\n",
       "      <td>6.578700e+07</td>\n",
       "      <td>4.150000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.883100e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>7700.100098</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>13246.870117</td>\n",
       "      <td>AAME</td>\n",
       "      <td>72.035038</td>\n",
       "      <td>74.407595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>-2.169300e+07</td>\n",
       "      <td>4.774500e+07</td>\n",
       "      <td>6.943800e+07</td>\n",
       "      <td>3.941500e+07</td>\n",
       "      <td>-2.445900e+07</td>\n",
       "      <td>3.380000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.380000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>8972.599609</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>12870.000000</td>\n",
       "      <td>AAME</td>\n",
       "      <td>43.436691</td>\n",
       "      <td>6.598978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>-2.517500e+07</td>\n",
       "      <td>4.312700e+07</td>\n",
       "      <td>6.830200e+07</td>\n",
       "      <td>3.863100e+07</td>\n",
       "      <td>-2.768600e+07</td>\n",
       "      <td>5.560000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.560000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>7999.339844</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>11085.250000</td>\n",
       "      <td>AAME</td>\n",
       "      <td>38.577060</td>\n",
       "      <td>-28.519854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>-1.980400e+07</td>\n",
       "      <td>4.637000e+07</td>\n",
       "      <td>6.617400e+07</td>\n",
       "      <td>3.541800e+07</td>\n",
       "      <td>-2.276400e+07</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>6635.279785</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>8972.599609</td>\n",
       "      <td>AAME</td>\n",
       "      <td>35.225641</td>\n",
       "      <td>-18.257263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.127700e+07</td>\n",
       "      <td>5.232600e+07</td>\n",
       "      <td>5.466100e+07</td>\n",
       "      <td>4.104900e+07</td>\n",
       "      <td>-1.316100e+07</td>\n",
       "      <td>1.361200e+07</td>\n",
       "      <td>10826000.0</td>\n",
       "      <td>2.443800e+07</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7559</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>13119.429688</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>13694.620117</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>4.384264</td>\n",
       "      <td>-69.113697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>1.919000e+07</td>\n",
       "      <td>7.485700e+07</td>\n",
       "      <td>7.228100e+07</td>\n",
       "      <td>5.741800e+07</td>\n",
       "      <td>-6.779000e+06</td>\n",
       "      <td>1.476300e+07</td>\n",
       "      <td>11206000.0</td>\n",
       "      <td>2.596900e+07</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0780</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>11890.929688</td>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>15971.589844</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>34.317419</td>\n",
       "      <td>-41.516967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1.373600e+07</td>\n",
       "      <td>6.384600e+07</td>\n",
       "      <td>6.562700e+07</td>\n",
       "      <td>5.148600e+07</td>\n",
       "      <td>-1.110800e+07</td>\n",
       "      <td>1.404100e+07</td>\n",
       "      <td>10803000.0</td>\n",
       "      <td>2.484400e+07</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1008</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>11108.070313</td>\n",
       "      <td>2021-08-06</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>14835.759766</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>33.558389</td>\n",
       "      <td>-52.491694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>6.338000e+06</td>\n",
       "      <td>3.915100e+07</td>\n",
       "      <td>5.373400e+07</td>\n",
       "      <td>3.412900e+07</td>\n",
       "      <td>-1.779400e+07</td>\n",
       "      <td>1.357400e+07</td>\n",
       "      <td>10558000.0</td>\n",
       "      <td>2.413200e+07</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.1525</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>8979.660156</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>7.580000</td>\n",
       "      <td>13752.240234</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>53.148783</td>\n",
       "      <td>-37.868852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1.133600e+07</td>\n",
       "      <td>4.865800e+07</td>\n",
       "      <td>5.011500e+07</td>\n",
       "      <td>3.732200e+07</td>\n",
       "      <td>-1.205400e+07</td>\n",
       "      <td>1.279300e+07</td>\n",
       "      <td>10597000.0</td>\n",
       "      <td>2.339000e+07</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.6369</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>8566.480469</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>9.325000</td>\n",
       "      <td>13192.349609</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>53.999646</td>\n",
       "      <td>-2.458165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>1.197600e+07</td>\n",
       "      <td>4.488900e+07</td>\n",
       "      <td>4.671400e+07</td>\n",
       "      <td>3.410800e+07</td>\n",
       "      <td>-1.099600e+07</td>\n",
       "      <td>1.250600e+07</td>\n",
       "      <td>10466000.0</td>\n",
       "      <td>2.297200e+07</td>\n",
       "      <td>347000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.1596</td>\n",
       "      <td>11.710000</td>\n",
       "      <td>8410.629883</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>11890.929688</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>41.379776</td>\n",
       "      <td>-14.432106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1.053800e+07</td>\n",
       "      <td>4.213700e+07</td>\n",
       "      <td>4.618800e+07</td>\n",
       "      <td>3.287300e+07</td>\n",
       "      <td>-1.382800e+07</td>\n",
       "      <td>1.321500e+07</td>\n",
       "      <td>11151000.0</td>\n",
       "      <td>2.436600e+07</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5556</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>7862.830078</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>11108.070313</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>41.273183</td>\n",
       "      <td>47.404507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>1.235100e+07</td>\n",
       "      <td>5.148100e+07</td>\n",
       "      <td>5.935100e+07</td>\n",
       "      <td>4.036800e+07</td>\n",
       "      <td>-1.186900e+07</td>\n",
       "      <td>1.303500e+07</td>\n",
       "      <td>11185000.0</td>\n",
       "      <td>2.422000e+07</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.5962</td>\n",
       "      <td>12.060000</td>\n",
       "      <td>7943.319824</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>8979.660156</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>13.046690</td>\n",
       "      <td>1.160857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.053700e+07</td>\n",
       "      <td>5.801800e+07</td>\n",
       "      <td>5.895300e+07</td>\n",
       "      <td>4.748100e+07</td>\n",
       "      <td>-1.227700e+07</td>\n",
       "      <td>1.147200e+07</td>\n",
       "      <td>11342000.0</td>\n",
       "      <td>2.281400e+07</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.3379</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>7459.709961</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>11.280000</td>\n",
       "      <td>9576.589844</td>\n",
       "      <td>AAOI</td>\n",
       "      <td>28.377509</td>\n",
       "      <td>-22.739730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fiscalDateEnding   grossProfit  totalRevenue  costOfRevenue  \\\n",
       "0        2020-12-31  4.027000e+09  4.027000e+09   4.485000e+09   \n",
       "1        2020-09-30 -2.310000e+09  2.833000e+09   5.143000e+09   \n",
       "2        2020-06-30 -2.601000e+09  1.368000e+09   3.969000e+09   \n",
       "3        2020-03-31  1.241000e+09  8.258000e+09   7.017000e+09   \n",
       "4        2019-12-31  1.118900e+10  1.131300e+10   1.240000e+08   \n",
       "5        2019-09-30  4.329000e+09  1.162700e+10   7.298000e+09   \n",
       "6        2019-06-30  4.615000e+09  1.168500e+10   7.070000e+09   \n",
       "7        2018-12-31  1.071100e+10  1.093800e+10   2.270000e+08   \n",
       "8        2018-09-30  4.077000e+09  1.129400e+10   7.217000e+09   \n",
       "9        2018-06-30  4.369000e+09  1.137700e+10   7.008000e+09   \n",
       "10       2018-03-31  3.648000e+09  1.013600e+10   6.488000e+09   \n",
       "11       2017-12-31  1.046100e+10  1.060000e+10   1.390000e+08   \n",
       "12       2017-09-30  4.315000e+09  1.061200e+10   6.297000e+09   \n",
       "13       2017-03-31  3.556000e+09  9.367000e+09   5.811000e+09   \n",
       "14       2020-09-30 -1.216900e+07  4.626900e+07   5.843800e+07   \n",
       "15       2020-06-30 -4.415000e+06  4.973700e+07   5.415200e+07   \n",
       "16       2020-03-31 -2.792200e+07  3.941000e+07   6.733200e+07   \n",
       "17       2019-12-31 -5.366300e+07  5.228900e+07   1.059520e+08   \n",
       "18       2019-09-30 -2.169300e+07  4.774500e+07   6.943800e+07   \n",
       "19       2019-06-30 -2.517500e+07  4.312700e+07   6.830200e+07   \n",
       "20       2018-09-30 -1.980400e+07  4.637000e+07   6.617400e+07   \n",
       "21       2020-12-31  1.127700e+07  5.232600e+07   5.466100e+07   \n",
       "22       2020-09-30  1.919000e+07  7.485700e+07   7.228100e+07   \n",
       "23       2020-06-30  1.373600e+07  6.384600e+07   6.562700e+07   \n",
       "24       2020-03-31  6.338000e+06  3.915100e+07   5.373400e+07   \n",
       "25       2019-12-31  1.133600e+07  4.865800e+07   5.011500e+07   \n",
       "26       2019-09-30  1.197600e+07  4.488900e+07   4.671400e+07   \n",
       "27       2019-06-30  1.053800e+07  4.213700e+07   4.618800e+07   \n",
       "28       2019-03-31  1.235100e+07  5.148100e+07   5.935100e+07   \n",
       "29       2018-12-31  1.053700e+07  5.801800e+07   5.895300e+07   \n",
       "\n",
       "    costofGoodsAndServicesSold  operatingIncome  \\\n",
       "0                 1.240000e+09    -2.515000e+09   \n",
       "1                 1.156000e+09    -2.871000e+09   \n",
       "2                 8.660000e+08    -2.486000e+09   \n",
       "3                 2.197000e+09    -2.549000e+09   \n",
       "4                 2.633000e+09     7.290000e+08   \n",
       "5                 2.854000e+09     8.080000e+08   \n",
       "6                 2.864000e+09     1.153000e+09   \n",
       "7                 2.748000e+09     5.710000e+08   \n",
       "8                 3.043000e+09     6.850000e+08   \n",
       "9                 2.898000e+09     1.004000e+09   \n",
       "10                2.529000e+09     3.960000e+08   \n",
       "11                2.395000e+09     6.380000e+08   \n",
       "12                2.345000e+09     1.256000e+09   \n",
       "13                2.137000e+09     7.370000e+08   \n",
       "14                         NaN    -1.522100e+07   \n",
       "15                         NaN    -7.527000e+06   \n",
       "16                         NaN    -3.122700e+07   \n",
       "17                6.713900e+07     6.578700e+07   \n",
       "18                3.941500e+07    -2.445900e+07   \n",
       "19                3.863100e+07    -2.768600e+07   \n",
       "20                3.541800e+07    -2.276400e+07   \n",
       "21                4.104900e+07    -1.316100e+07   \n",
       "22                5.741800e+07    -6.779000e+06   \n",
       "23                5.148600e+07    -1.110800e+07   \n",
       "24                3.412900e+07    -1.779400e+07   \n",
       "25                3.732200e+07    -1.205400e+07   \n",
       "26                3.410800e+07    -1.099600e+07   \n",
       "27                3.287300e+07    -1.382800e+07   \n",
       "28                4.036800e+07    -1.186900e+07   \n",
       "29                4.748100e+07    -1.227700e+07   \n",
       "\n",
       "    sellingGeneralAndAdministrative  researchAndDevelopment  \\\n",
       "0                      1.860000e+08                     NaN   \n",
       "1                      7.000000e+07                     NaN   \n",
       "2                      4.300000e+07                     NaN   \n",
       "3                      3.050000e+08                     NaN   \n",
       "4                      5.030000e+08                     NaN   \n",
       "5                      4.240000e+08                     NaN   \n",
       "6                      4.010000e+08                     NaN   \n",
       "7                      4.720000e+08                     NaN   \n",
       "8                      3.950000e+08                     NaN   \n",
       "9                      3.478000e+09                     NaN   \n",
       "10                     3.373000e+09                     NaN   \n",
       "11                     6.175000e+09                     NaN   \n",
       "12                     3.395000e+09                     NaN   \n",
       "13                     3.143000e+09                     NaN   \n",
       "14                     1.160000e+05                     NaN   \n",
       "15                     4.080000e+05                     NaN   \n",
       "16                     3.530000e+05                     NaN   \n",
       "17                     4.150000e+05                     NaN   \n",
       "18                     3.380000e+05                     NaN   \n",
       "19                     5.560000e+05                     NaN   \n",
       "20                     7.000000e+04                     NaN   \n",
       "21                     1.361200e+07              10826000.0   \n",
       "22                     1.476300e+07              11206000.0   \n",
       "23                     1.404100e+07              10803000.0   \n",
       "24                     1.357400e+07              10558000.0   \n",
       "25                     1.279300e+07              10597000.0   \n",
       "26                     1.250600e+07              10466000.0   \n",
       "27                     1.321500e+07              11151000.0   \n",
       "28                     1.303500e+07              11185000.0   \n",
       "29                     1.147200e+07              11342000.0   \n",
       "\n",
       "    operatingExpenses  investmentIncomeNet  ...  surprisePercentage  \\\n",
       "0        1.127000e+09            5000000.0  ...              6.3380   \n",
       "1        1.941000e+09            5000000.0  ...              3.7309   \n",
       "2        1.133000e+09           10000000.0  ...              0.9575   \n",
       "3        2.857000e+09           21000000.0  ...            -12.5218   \n",
       "4        1.240000e+08           24000000.0  ...             -0.5104   \n",
       "5        2.508000e+09           34000000.0  ...              1.6100   \n",
       "6        2.277000e+09           35000000.0  ...              1.7726   \n",
       "7        2.270000e+08           34000000.0  ...              3.4106   \n",
       "8        2.341000e+09           29000000.0  ...              0.4177   \n",
       "9        5.441000e+09           30000000.0  ...              2.4706   \n",
       "10       5.220000e+09           25000000.0  ...              5.6041   \n",
       "11       1.390000e+08           24000000.0  ...              3.2833   \n",
       "12       5.172000e+09           25000000.0  ...              1.5737   \n",
       "13       4.828000e+09           21000000.0  ...              6.5688   \n",
       "14       1.160000e+05                  NaN  ...                 NaN   \n",
       "15       4.080000e+05                  NaN  ...                 NaN   \n",
       "16       3.530000e+05                  NaN  ...                 NaN   \n",
       "17       7.883100e+07                  NaN  ...                 NaN   \n",
       "18       3.380000e+05                  NaN  ...                 NaN   \n",
       "19       5.560000e+05                  NaN  ...                 NaN   \n",
       "20       7.000000e+04                  NaN  ...                 NaN   \n",
       "21       2.443800e+07              35000.0  ...             13.7559   \n",
       "22       2.596900e+07              26000.0  ...             29.0780   \n",
       "23       2.484400e+07              47000.0  ...              5.1008   \n",
       "24       2.413200e+07             147000.0  ...            -18.1525   \n",
       "25       2.339000e+07             196000.0  ...             21.6369   \n",
       "26       2.297200e+07             347000.0  ...             37.1596   \n",
       "27       2.436600e+07             310000.0  ...             30.5556   \n",
       "28       2.422000e+07              72000.0  ...            -24.5962   \n",
       "29       2.281400e+07              59000.0  ...             54.3379   \n",
       "\n",
       "        price    nasd_price  next_year_date  next_year_price  nasd_ny_price  \\\n",
       "0   18.100000  13337.160156      2022-01-28        15.640000   13770.570313   \n",
       "1   13.150000  11506.009766      2021-10-22        19.150000   15090.200195   \n",
       "2   11.770000  10461.419922      2021-07-23        21.200001   14836.990234   \n",
       "3   12.010000   8889.549805      2021-04-30        21.719999   13962.679688   \n",
       "4   28.799999   9402.480469      2021-01-22        15.820000   13543.059570   \n",
       "5   29.410000   8185.799805      2020-10-23        12.600000   11548.280273   \n",
       "6   31.670000   8238.540039      2020-07-24        11.390000   10363.179688   \n",
       "7   33.660000   7073.459961      2020-01-24        27.639999    9314.910156   \n",
       "8   32.369999   7318.339844      2019-10-25        30.860001    8243.120117   \n",
       "9   40.020000   7852.180176      2019-07-26        31.240000    8330.209961   \n",
       "10  42.369999   7118.680176      2019-04-26        33.060001    8146.399902   \n",
       "11  53.049999   7411.160156      2019-01-25        34.980000    7164.859863   \n",
       "12  48.610001   6556.770020      2018-10-26        32.459999    7167.209961   \n",
       "13  43.980000   6048.939941      2018-04-27        43.400002    7119.799805   \n",
       "14   2.060000  12888.280273      2021-12-31         2.450000   15644.969727   \n",
       "15   2.000000  11167.509766      2021-09-30         4.150000   14448.580078   \n",
       "16   1.660000  10058.769531      2021-06-30         4.320000   14503.950195   \n",
       "17   2.110000   7700.100098      2021-03-31         3.680000   13246.870117   \n",
       "18   1.970000   8972.599609      2020-12-30         2.100000   12870.000000   \n",
       "19   2.770000   7999.339844      2020-09-29         1.980000   11085.250000   \n",
       "20   2.410000   6635.279785      2019-12-31         1.970000    8972.599609   \n",
       "21  11.170000  13119.429688      2022-02-25         3.450000   13694.620117   \n",
       "22  10.020000  11890.929688      2021-11-05         5.860000   15971.589844   \n",
       "23  15.050000  11108.070313      2021-08-06         7.150000   14835.759766   \n",
       "24  12.200000   8979.660156      2021-05-07         7.580000   13752.240234   \n",
       "25   9.560000   8566.480469      2021-02-26         9.325000   13192.349609   \n",
       "26  11.710000   8410.629883      2020-11-05        10.020000   11890.929688   \n",
       "27  10.210000   7862.830078      2020-08-06        15.050000   11108.070313   \n",
       "28  12.060000   7943.319824      2020-05-07        12.200000    8979.660156   \n",
       "29  14.600000   7459.709961      2020-02-21        11.280000    9576.589844   \n",
       "\n",
       "    symbol  Nasdaq_Performance  Stock_Performance  Label  \n",
       "0      AAL            3.249643         -13.591160      0  \n",
       "1      AAL           31.150594          45.627378      1  \n",
       "2      AAL           41.825778          80.118946      1  \n",
       "3      AAL           57.068468          80.849283      1  \n",
       "4      AAL           44.037093         -45.069444      0  \n",
       "5      AAL           41.076994         -57.157428      0  \n",
       "6      AAL           25.789031         -64.035364      0  \n",
       "7      AAL           31.688173         -17.884731      0  \n",
       "8      AAL           12.636476          -4.664808      0  \n",
       "9      AAL            6.087861         -21.939032      0  \n",
       "10     AAL           14.436942         -21.973089      0  \n",
       "11     AAL           -3.323370         -34.062205      0  \n",
       "12     AAL            9.310071         -33.223619      0  \n",
       "13     AAL           17.703265          -1.318777      0  \n",
       "14    AAME           21.389118          18.932044      0  \n",
       "15    AAME           29.380501         107.500005      1  \n",
       "16    AAME           44.192092         160.240979      1  \n",
       "17    AAME           72.035038          74.407595      1  \n",
       "18    AAME           43.436691           6.598978      0  \n",
       "19    AAME           38.577060         -28.519854      0  \n",
       "20    AAME           35.225641         -18.257263      0  \n",
       "21    AAOI            4.384264         -69.113697      0  \n",
       "22    AAOI           34.317419         -41.516967      0  \n",
       "23    AAOI           33.558389         -52.491694      0  \n",
       "24    AAOI           53.148783         -37.868852      0  \n",
       "25    AAOI           53.999646          -2.458165      0  \n",
       "26    AAOI           41.379776         -14.432106      0  \n",
       "27    AAOI           41.273183          47.404507      1  \n",
       "28    AAOI           13.046690           1.160857      0  \n",
       "29    AAOI           28.377509         -22.739730      0  \n",
       "\n",
       "[30 rows x 102 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d42ed991-bb38-4894-9d73-ca6c44fa09df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7887, 102)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1423273c-b915-457d-b354-26deb98b0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = df.isnull().mean().sort_values(ascending = False).head(45).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e4fb8563-6cb1-48aa-8841-46d91020c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = list(cols_to_drop) + ['fiscalDateEnding','reportedDate','price','nasd_price','next_year_date','next_year_price','nasd_ny_price','symbol','Nasdaq_Performance', 'Stock_Performance','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5595e65e-af6b-4fc8-91ee-f0b9cade8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'Label')\n",
    "y = df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4864f8ab-dbd8-4989-9188-93fec2d10ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "737fbb5d-0b88-4f74-96b0-cf1d1a90eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "\n",
    "for colum in cols_to_drop:\n",
    "    columns.remove(colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f2269ce-cc53-43a9-8c80-01bcb978e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = make_column_transformer((SimpleImputer(strategy = 'constant',fill_value=0),columns),\n",
    "                                              remainder=\"drop\")\n",
    "\n",
    "pipline = make_pipeline(column_transformer, StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0e20c2fa-7973-4a07-b416-e4983a11f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipline.fit_transform(X_train)\n",
    "X_test = pipline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "567984b5-049d-4e00-83fe-63ebf6f09eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6309, 46)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e3cfa112-9676-4b09-8805-467dbea1bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def initialize_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(1024, activation='relu', input_dim=46))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='BinaryCrossentropy', \n",
    "                  optimizer=Adam(learning_rate=0.0005), \n",
    "                  metrics=['accuracy',metrics.Precision()]) \n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f87ed21c-b4d2-45da-832b-f504a002df43",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.6188 - accuracy: 0.6701 - precision_10: 0.6147 - val_loss: 3.2153 - val_accuracy: 0.6712 - val_precision_10: 0.5385\n",
      "Epoch 2/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6209 - accuracy: 0.6689 - precision_10: 0.5905 - val_loss: 6.1543 - val_accuracy: 0.6696 - val_precision_10: 0.4762\n",
      "Epoch 3/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6177 - accuracy: 0.6711 - precision_10: 0.6875 - val_loss: 20.9075 - val_accuracy: 0.6688 - val_precision_10: 0.4583\n",
      "Epoch 4/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6691 - accuracy: 0.6709 - precision_10: 0.6465 - val_loss: 6.1431 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 5/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6189 - accuracy: 0.6705 - precision_10: 0.6134 - val_loss: 4.1369 - val_accuracy: 0.6609 - val_precision_10: 0.3846\n",
      "Epoch 6/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6166 - accuracy: 0.6713 - precision_10: 0.5838 - val_loss: 4.3670 - val_accuracy: 0.6696 - val_precision_10: 0.4706\n",
      "Epoch 7/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6165 - accuracy: 0.6713 - precision_10: 0.6115 - val_loss: 3.6222 - val_accuracy: 0.6577 - val_precision_10: 0.3857\n",
      "Epoch 8/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6159 - accuracy: 0.6715 - precision_10: 0.6333 - val_loss: 8.0837 - val_accuracy: 0.6672 - val_precision_10: 0.3889\n",
      "Epoch 9/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6166 - accuracy: 0.6691 - precision_10: 0.5694 - val_loss: 10.1572 - val_accuracy: 0.6672 - val_precision_10: 0.3889\n",
      "Epoch 10/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6161 - accuracy: 0.6695 - precision_10: 0.6375 - val_loss: 3.1673 - val_accuracy: 0.6680 - val_precision_10: 0.4211\n",
      "Epoch 11/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6175 - accuracy: 0.6697 - precision_10: 0.5782 - val_loss: 5.6712 - val_accuracy: 0.6688 - val_precision_10: 0.4643\n",
      "Epoch 12/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6170 - accuracy: 0.6709 - precision_10: 0.6835 - val_loss: 2.8003 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 13/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6157 - accuracy: 0.6709 - precision_10: 0.6986 - val_loss: 3.0449 - val_accuracy: 0.6640 - val_precision_10: 0.3182\n",
      "Epoch 14/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6350 - accuracy: 0.6697 - precision_10: 0.6162 - val_loss: 31.0580 - val_accuracy: 0.6601 - val_precision_10: 0.4177\n",
      "Epoch 15/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.7844 - accuracy: 0.6689 - precision_10: 0.5442 - val_loss: 0.6472 - val_accuracy: 0.6712 - val_precision_10: 1.0000\n",
      "Epoch 16/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6995 - accuracy: 0.6673 - precision_10: 0.6897 - val_loss: 0.9239 - val_accuracy: 0.6680 - val_precision_10: 0.4286\n",
      "Epoch 17/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.6206 - accuracy: 0.6697 - precision_10: 0.6211 - val_loss: 5.6914 - val_accuracy: 0.6593 - val_precision_10: 0.3158\n",
      "Epoch 18/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6602 - accuracy: 0.6691 - precision_10: 0.5769 - val_loss: 0.8133 - val_accuracy: 0.6680 - val_precision_10: 0.4000\n",
      "Epoch 19/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6227 - accuracy: 0.6691 - precision_10: 0.6136 - val_loss: 3.1382 - val_accuracy: 0.6680 - val_precision_10: 0.4348\n",
      "Epoch 20/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6373 - accuracy: 0.6697 - precision_10: 0.6825 - val_loss: 1.3541 - val_accuracy: 0.6696 - val_precision_10: 0.3333\n",
      "Epoch 21/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.6176 - accuracy: 0.6705 - precision_10: 0.7647 - val_loss: 2.2507 - val_accuracy: 0.6696 - val_precision_10: 0.4706\n",
      "Epoch 22/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.6138 - accuracy: 0.6707 - precision_10: 0.7414 - val_loss: 3.9072 - val_accuracy: 0.6688 - val_precision_10: 0.4500\n",
      "Epoch 23/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6134 - accuracy: 0.6705 - precision_10: 0.6588 - val_loss: 5.1826 - val_accuracy: 0.6672 - val_precision_10: 0.4333\n",
      "Epoch 24/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.6129 - accuracy: 0.6727 - precision_10: 0.6638 - val_loss: 5.5578 - val_accuracy: 0.6688 - val_precision_10: 0.4643\n",
      "Epoch 25/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6132 - accuracy: 0.6705 - precision_10: 0.6588 - val_loss: 6.5224 - val_accuracy: 0.6616 - val_precision_10: 0.3878\n",
      "Epoch 26/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6117 - accuracy: 0.6719 - precision_10: 0.6000 - val_loss: 4.0531 - val_accuracy: 0.6672 - val_precision_10: 0.4286\n",
      "Epoch 27/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.6217 - accuracy: 0.6701 - precision_10: 0.6437 - val_loss: 9.0826 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 28/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6148 - accuracy: 0.6711 - precision_10: 0.7586 - val_loss: 4.8569 - val_accuracy: 0.6680 - val_precision_10: 0.4211\n",
      "Epoch 29/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.6256 - accuracy: 0.6709 - precision_10: 0.6933 - val_loss: 0.7434 - val_accuracy: 0.6696 - val_precision_10: 0.4545\n",
      "Epoch 30/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6143 - accuracy: 0.6711 - precision_10: 0.7419 - val_loss: 3.2556 - val_accuracy: 0.6696 - val_precision_10: 0.4762\n",
      "Epoch 31/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 1.0598 - accuracy: 0.6671 - precision_10: 0.5481 - val_loss: 1.0498 - val_accuracy: 0.6688 - val_precision_10: 0.4583\n",
      "Epoch 32/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6310 - accuracy: 0.6695 - precision_10: 0.6719 - val_loss: 1.2777 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 33/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.6154 - accuracy: 0.6713 - precision_10: 0.6867 - val_loss: 1.4934 - val_accuracy: 0.6696 - val_precision_10: 0.4545\n",
      "Epoch 34/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6144 - accuracy: 0.6707 - precision_10: 0.6458 - val_loss: 0.9610 - val_accuracy: 0.6688 - val_precision_10: 0.4286\n",
      "Epoch 35/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6132 - accuracy: 0.6705 - precision_10: 0.6080 - val_loss: 1.4803 - val_accuracy: 0.6593 - val_precision_10: 0.3793\n",
      "Epoch 36/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.6128 - accuracy: 0.6709 - precision_10: 0.6160 - val_loss: 1.3357 - val_accuracy: 0.6616 - val_precision_10: 0.3962\n",
      "Epoch 37/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6129 - accuracy: 0.6703 - precision_10: 0.6444 - val_loss: 2.2353 - val_accuracy: 0.6545 - val_precision_10: 0.3750\n",
      "Epoch 38/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6327 - accuracy: 0.6685 - precision_10: 0.5277 - val_loss: 0.8369 - val_accuracy: 0.6585 - val_precision_10: 0.4000\n",
      "Epoch 39/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6135 - accuracy: 0.6721 - precision_10: 0.5907 - val_loss: 2.0986 - val_accuracy: 0.6585 - val_precision_10: 0.4194\n",
      "Epoch 40/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6132 - accuracy: 0.6747 - precision_10: 0.5984 - val_loss: 2.0005 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 41/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6118 - accuracy: 0.6711 - precision_10: 0.6103 - val_loss: 1.8662 - val_accuracy: 0.6632 - val_precision_10: 0.4615\n",
      "Epoch 42/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.6113 - accuracy: 0.6719 - precision_10: 0.6000 - val_loss: 0.9701 - val_accuracy: 0.6609 - val_precision_10: 0.4302\n",
      "Epoch 43/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6102 - accuracy: 0.6729 - precision_10: 0.5652 - val_loss: 2.5075 - val_accuracy: 0.6664 - val_precision_10: 0.4490\n",
      "Epoch 44/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.6121 - accuracy: 0.6723 - precision_10: 0.5562 - val_loss: 1.1746 - val_accuracy: 0.6648 - val_precision_10: 0.4103\n",
      "Epoch 45/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6108 - accuracy: 0.6756 - precision_10: 0.6992 - val_loss: 1.6557 - val_accuracy: 0.6624 - val_precision_10: 0.3810\n",
      "Epoch 46/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6247 - accuracy: 0.6719 - precision_10: 0.5685 - val_loss: 0.9661 - val_accuracy: 0.6632 - val_precision_10: 0.3043\n",
      "Epoch 47/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6607 - accuracy: 0.6693 - precision_10: 0.5475 - val_loss: 0.8737 - val_accuracy: 0.6696 - val_precision_10: 0.4444\n",
      "Epoch 48/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6165 - accuracy: 0.6687 - precision_10: 0.5464 - val_loss: 0.9832 - val_accuracy: 0.6696 - val_precision_10: 0.4545\n",
      "Epoch 49/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6150 - accuracy: 0.6727 - precision_10: 0.6173 - val_loss: 1.3986 - val_accuracy: 0.6656 - val_precision_10: 0.4722\n",
      "Epoch 50/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6123 - accuracy: 0.6737 - precision_10: 0.5811 - val_loss: 1.2918 - val_accuracy: 0.6688 - val_precision_10: 0.4500\n",
      "Epoch 51/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.6113 - accuracy: 0.6762 - precision_10: 0.6111 - val_loss: 1.1535 - val_accuracy: 0.6664 - val_precision_10: 0.3913\n",
      "Epoch 52/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6094 - accuracy: 0.6756 - precision_10: 0.6345 - val_loss: 1.2500 - val_accuracy: 0.6672 - val_precision_10: 0.4412\n",
      "Epoch 53/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6101 - accuracy: 0.6760 - precision_10: 0.6054 - val_loss: 1.7643 - val_accuracy: 0.6648 - val_precision_10: 0.3704\n",
      "Epoch 54/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6128 - accuracy: 0.6741 - precision_10: 0.6510 - val_loss: 1.4686 - val_accuracy: 0.6696 - val_precision_10: 0.4706\n",
      "Epoch 55/500\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.6936 - accuracy: 0.6788 - precision_10: 0.6364 - val_loss: 0.6587 - val_accuracy: 0.6664 - val_precision_10: 0.4000\n",
      "Epoch 56/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.6473 - accuracy: 0.6737 - precision_10: 0.6150 - val_loss: 0.7313 - val_accuracy: 0.6696 - val_precision_10: 0.4706\n",
      "Epoch 57/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.6135 - accuracy: 0.6737 - precision_10: 0.5850 - val_loss: 0.9542 - val_accuracy: 0.6680 - val_precision_10: 0.4400\n",
      "Epoch 58/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.6101 - accuracy: 0.6762 - precision_10: 0.6346 - val_loss: 1.0265 - val_accuracy: 0.6696 - val_precision_10: 0.4865\n",
      "Epoch 59/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6398 - accuracy: 0.6707 - precision_10: 0.5667 - val_loss: 0.8089 - val_accuracy: 0.6672 - val_precision_10: 0.4444\n",
      "Epoch 60/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6150 - accuracy: 0.6751 - precision_10: 0.6316 - val_loss: 1.0494 - val_accuracy: 0.6648 - val_precision_10: 0.3704\n",
      "Epoch 61/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6125 - accuracy: 0.6764 - precision_10: 0.5966 - val_loss: 0.9546 - val_accuracy: 0.6593 - val_precision_10: 0.4314\n",
      "Epoch 62/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6131 - accuracy: 0.6788 - precision_10: 0.6481 - val_loss: 0.9933 - val_accuracy: 0.6593 - val_precision_10: 0.3833\n",
      "Epoch 63/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6156 - accuracy: 0.6751 - precision_10: 0.6359 - val_loss: 1.0460 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 64/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6092 - accuracy: 0.6760 - precision_10: 0.6554 - val_loss: 1.3730 - val_accuracy: 0.6640 - val_precision_10: 0.4524\n",
      "Epoch 65/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6077 - accuracy: 0.6830 - precision_10: 0.6705 - val_loss: 0.9722 - val_accuracy: 0.6672 - val_precision_10: 0.3889\n",
      "Epoch 66/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6089 - accuracy: 0.6776 - precision_10: 0.6452 - val_loss: 1.0757 - val_accuracy: 0.6609 - val_precision_10: 0.3800\n",
      "Epoch 67/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6048 - accuracy: 0.6790 - precision_10: 0.6636 - val_loss: 1.9930 - val_accuracy: 0.6632 - val_precision_10: 0.3902\n",
      "Epoch 68/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6119 - accuracy: 0.6800 - precision_10: 0.6569 - val_loss: 4.0645 - val_accuracy: 0.6521 - val_precision_10: 0.4268\n",
      "Epoch 69/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6059 - accuracy: 0.6758 - precision_10: 0.6195 - val_loss: 4.9871 - val_accuracy: 0.6577 - val_precision_10: 0.4149\n",
      "Epoch 70/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6047 - accuracy: 0.6790 - precision_10: 0.6549 - val_loss: 2.3682 - val_accuracy: 0.6680 - val_precision_10: 0.4483\n",
      "Epoch 71/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6030 - accuracy: 0.6802 - precision_10: 0.6667 - val_loss: 3.0430 - val_accuracy: 0.6640 - val_precision_10: 0.3889\n",
      "Epoch 72/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.8685 - accuracy: 0.6768 - precision_10: 0.6928 - val_loss: 0.7802 - val_accuracy: 0.6688 - val_precision_10: 0.4583\n",
      "Epoch 73/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6098 - accuracy: 0.6802 - precision_10: 0.6810 - val_loss: 1.0077 - val_accuracy: 0.6672 - val_precision_10: 0.4167\n",
      "Epoch 74/500\n",
      "316/316 [==============================] - 12s 36ms/step - loss: 0.6065 - accuracy: 0.6804 - precision_10: 0.6878 - val_loss: 1.1817 - val_accuracy: 0.6664 - val_precision_10: 0.4074\n",
      "Epoch 75/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.6044 - accuracy: 0.6800 - precision_10: 0.7419 - val_loss: 1.6658 - val_accuracy: 0.6664 - val_precision_10: 0.4138\n",
      "Epoch 76/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.6041 - accuracy: 0.6804 - precision_10: 0.7421 - val_loss: 1.2901 - val_accuracy: 0.6656 - val_precision_10: 0.4167\n",
      "Epoch 77/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6048 - accuracy: 0.6820 - precision_10: 0.6977 - val_loss: 1.4612 - val_accuracy: 0.6640 - val_precision_10: 0.4130\n",
      "Epoch 78/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6008 - accuracy: 0.6824 - precision_10: 0.6246 - val_loss: 1.3333 - val_accuracy: 0.6696 - val_precision_10: 0.4783\n",
      "Epoch 79/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.6062 - accuracy: 0.6798 - precision_10: 0.7079 - val_loss: 1.5776 - val_accuracy: 0.6561 - val_precision_10: 0.4100\n",
      "Epoch 80/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6017 - accuracy: 0.6814 - precision_10: 0.6444 - val_loss: 1.3192 - val_accuracy: 0.6680 - val_precision_10: 0.4400\n",
      "Epoch 81/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6062 - accuracy: 0.6790 - precision_10: 0.6483 - val_loss: 1.0413 - val_accuracy: 0.6609 - val_precision_10: 0.3696\n",
      "Epoch 82/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.6002 - accuracy: 0.6822 - precision_10: 0.6870 - val_loss: 1.6283 - val_accuracy: 0.6609 - val_precision_10: 0.3571\n",
      "Epoch 83/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5976 - accuracy: 0.6820 - precision_10: 0.6995 - val_loss: 1.9151 - val_accuracy: 0.6577 - val_precision_10: 0.3400\n",
      "Epoch 84/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5994 - accuracy: 0.6786 - precision_10: 0.7361 - val_loss: 1.9507 - val_accuracy: 0.6490 - val_precision_10: 0.3247\n",
      "Epoch 85/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5996 - accuracy: 0.6816 - precision_10: 0.6694 - val_loss: 1.7489 - val_accuracy: 0.6561 - val_precision_10: 0.3500\n",
      "Epoch 86/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.9062 - accuracy: 0.6854 - precision_10: 0.7008 - val_loss: 1.6929 - val_accuracy: 0.6609 - val_precision_10: 0.4167\n",
      "Epoch 87/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6015 - accuracy: 0.6792 - precision_10: 0.6414 - val_loss: 2.5949 - val_accuracy: 0.6609 - val_precision_10: 0.3696\n",
      "Epoch 88/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5984 - accuracy: 0.6836 - precision_10: 0.6962 - val_loss: 1.8250 - val_accuracy: 0.6688 - val_precision_10: 0.4688\n",
      "Epoch 89/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.6037 - accuracy: 0.6846 - precision_10: 0.7042 - val_loss: 3.1914 - val_accuracy: 0.6616 - val_precision_10: 0.3721\n",
      "Epoch 90/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5958 - accuracy: 0.6848 - precision_10: 0.6882 - val_loss: 2.9841 - val_accuracy: 0.6553 - val_precision_10: 0.3956\n",
      "Epoch 91/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.6195 - accuracy: 0.6838 - precision_10: 0.7009 - val_loss: 1.7004 - val_accuracy: 0.6616 - val_precision_10: 0.3962\n",
      "Epoch 92/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.6271 - accuracy: 0.6828 - precision_10: 0.7730 - val_loss: 2.4640 - val_accuracy: 0.6672 - val_precision_10: 0.4333\n",
      "Epoch 93/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5957 - accuracy: 0.6832 - precision_10: 0.7040 - val_loss: 2.6884 - val_accuracy: 0.6616 - val_precision_10: 0.3721\n",
      "Epoch 94/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5955 - accuracy: 0.6895 - precision_10: 0.6965 - val_loss: 2.0328 - val_accuracy: 0.6537 - val_precision_10: 0.4561\n",
      "Epoch 95/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5953 - accuracy: 0.6865 - precision_10: 0.6985 - val_loss: 2.8460 - val_accuracy: 0.6648 - val_precision_10: 0.4146\n",
      "Epoch 96/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5923 - accuracy: 0.6836 - precision_10: 0.6914 - val_loss: 3.2178 - val_accuracy: 0.6624 - val_precision_10: 0.4242\n",
      "Epoch 97/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5971 - accuracy: 0.6854 - precision_10: 0.6466 - val_loss: 2.6044 - val_accuracy: 0.6680 - val_precision_10: 0.4681\n",
      "Epoch 98/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5939 - accuracy: 0.6848 - precision_10: 0.6725 - val_loss: 1.8909 - val_accuracy: 0.6593 - val_precision_10: 0.3833\n",
      "Epoch 99/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5935 - accuracy: 0.6854 - precision_10: 0.7339 - val_loss: 3.4866 - val_accuracy: 0.6601 - val_precision_10: 0.4030\n",
      "Epoch 100/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5980 - accuracy: 0.6854 - precision_10: 0.6848 - val_loss: 1.7598 - val_accuracy: 0.6656 - val_precision_10: 0.4211\n",
      "Epoch 101/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5958 - accuracy: 0.6875 - precision_10: 0.7325 - val_loss: 2.3428 - val_accuracy: 0.6593 - val_precision_10: 0.3833\n",
      "Epoch 102/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6543 - accuracy: 0.6840 - precision_10: 0.6892 - val_loss: 1.3066 - val_accuracy: 0.6616 - val_precision_10: 0.3659\n",
      "Epoch 103/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.6004 - accuracy: 0.6846 - precision_10: 0.6828 - val_loss: 2.9355 - val_accuracy: 0.6601 - val_precision_10: 0.4058\n",
      "Epoch 104/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.5943 - accuracy: 0.6832 - precision_10: 0.6798 - val_loss: 4.2674 - val_accuracy: 0.6577 - val_precision_10: 0.3857\n",
      "Epoch 105/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5982 - accuracy: 0.6877 - precision_10: 0.6647 - val_loss: 3.9587 - val_accuracy: 0.6656 - val_precision_10: 0.4375\n",
      "Epoch 106/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5982 - accuracy: 0.6846 - precision_10: 0.6678 - val_loss: 2.9220 - val_accuracy: 0.6680 - val_precision_10: 0.4651\n",
      "Epoch 107/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5935 - accuracy: 0.6854 - precision_10: 0.6917 - val_loss: 2.2422 - val_accuracy: 0.6482 - val_precision_10: 0.3727\n",
      "Epoch 108/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5917 - accuracy: 0.6895 - precision_10: 0.7595 - val_loss: 2.7217 - val_accuracy: 0.6553 - val_precision_10: 0.3855\n",
      "Epoch 109/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5901 - accuracy: 0.6869 - precision_10: 0.7083 - val_loss: 4.7572 - val_accuracy: 0.6656 - val_precision_10: 0.4211\n",
      "Epoch 110/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5917 - accuracy: 0.6877 - precision_10: 0.7050 - val_loss: 4.3062 - val_accuracy: 0.6632 - val_precision_10: 0.4211\n",
      "Epoch 111/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5952 - accuracy: 0.6899 - precision_10: 0.7289 - val_loss: 3.2131 - val_accuracy: 0.6545 - val_precision_10: 0.4275 - loss: 0.5961 - acc\n",
      "Epoch 112/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5918 - accuracy: 0.6893 - precision_10: 0.7020 - val_loss: 2.9004 - val_accuracy: 0.6521 - val_precision_10: 0.4218\n",
      "Epoch 113/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.5885 - accuracy: 0.6901 - precision_10: 0.6740 - val_loss: 5.8216 - val_accuracy: 0.6553 - val_precision_10: 0.3623\n",
      "Epoch 114/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5947 - accuracy: 0.6877 - precision_10: 0.7262 - val_loss: 2.3052 - val_accuracy: 0.6672 - val_precision_10: 0.4167\n",
      "Epoch 115/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5961 - accuracy: 0.6776 - precision_10: 0.8182 - val_loss: 4.5295 - val_accuracy: 0.6569 - val_precision_10: 0.3867\n",
      "Epoch 116/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5916 - accuracy: 0.6905 - precision_10: 0.7078 - val_loss: 4.3942 - val_accuracy: 0.6561 - val_precision_10: 0.3875\n",
      "Epoch 117/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5882 - accuracy: 0.6852 - precision_10: 0.7285 - val_loss: 7.2328 - val_accuracy: 0.6561 - val_precision_10: 0.3750\n",
      "Epoch 118/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5914 - accuracy: 0.6885 - precision_10: 0.6928 - val_loss: 5.2835 - val_accuracy: 0.6537 - val_precision_10: 0.3918\n",
      "Epoch 119/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5958 - accuracy: 0.6885 - precision_10: 0.6657 - val_loss: 1.5751 - val_accuracy: 0.6577 - val_precision_10: 0.4000\n",
      "Epoch 120/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6548 - accuracy: 0.6865 - precision_10: 0.7030 - val_loss: 13.6971 - val_accuracy: 0.6664 - val_precision_10: 0.4545\n",
      "Epoch 121/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.6299 - accuracy: 0.6828 - precision_10: 0.7282 - val_loss: 5.6905 - val_accuracy: 0.6569 - val_precision_10: 0.3731\n",
      "Epoch 122/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5957 - accuracy: 0.6867 - precision_10: 0.6940 - val_loss: 2.7274 - val_accuracy: 0.6585 - val_precision_10: 0.3256\n",
      "Epoch 123/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6084 - accuracy: 0.6860 - precision_10: 0.6855 - val_loss: 5.8594 - val_accuracy: 0.6664 - val_precision_10: 0.4138\n",
      "Epoch 124/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5945 - accuracy: 0.6860 - precision_10: 0.7488 - val_loss: 4.8087 - val_accuracy: 0.6696 - val_precision_10: 0.4857\n",
      "Epoch 125/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.5943 - accuracy: 0.6881 - precision_10: 0.7900 - val_loss: 3.5290 - val_accuracy: 0.6506 - val_precision_10: 0.3626\n",
      "Epoch 126/500\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.5926 - accuracy: 0.6905 - precision_10: 0.7254 - val_loss: 4.9473 - val_accuracy: 0.6482 - val_precision_10: 0.3600\n",
      "Epoch 127/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5882 - accuracy: 0.6925 - precision_10: 0.7212 - val_loss: 4.0210 - val_accuracy: 0.6640 - val_precision_10: 0.4000\n",
      "Epoch 128/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5866 - accuracy: 0.6897 - precision_10: 0.7541 - val_loss: 7.6861 - val_accuracy: 0.6466 - val_precision_10: 0.3611\n",
      "Epoch 129/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5930 - accuracy: 0.6895 - precision_10: 0.7338 - val_loss: 2.3801 - val_accuracy: 0.6656 - val_precision_10: 0.4118\n",
      "Epoch 130/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5978 - accuracy: 0.6848 - precision_10: 0.7281 - val_loss: 1.9556 - val_accuracy: 0.6529 - val_precision_10: 0.3514\n",
      "Epoch 131/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5935 - accuracy: 0.6893 - precision_10: 0.7311 - val_loss: 1.3404 - val_accuracy: 0.6696 - val_precision_10: 0.4783\n",
      "Epoch 132/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5870 - accuracy: 0.6889 - precision_10: 0.7778 - val_loss: 2.0240 - val_accuracy: 0.6656 - val_precision_10: 0.4444\n",
      "Epoch 133/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5839 - accuracy: 0.6919 - precision_10: 0.6945 - val_loss: 2.6367 - val_accuracy: 0.6561 - val_precision_10: 0.3676\n",
      "Epoch 134/500\n",
      "316/316 [==============================] - 12s 36ms/step - loss: 0.5863 - accuracy: 0.6939 - precision_10: 0.7245 - val_loss: 2.7771 - val_accuracy: 0.6616 - val_precision_10: 0.4154\n",
      "Epoch 135/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5892 - accuracy: 0.6899 - precision_10: 0.7323 - val_loss: 2.3637 - val_accuracy: 0.6561 - val_precision_10: 0.3784\n",
      "Epoch 136/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5840 - accuracy: 0.6935 - precision_10: 0.7160 - val_loss: 3.5666 - val_accuracy: 0.6529 - val_precision_10: 0.3382\n",
      "Epoch 137/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5905 - accuracy: 0.6875 - precision_10: 0.7100 - val_loss: 2.2260 - val_accuracy: 0.6688 - val_precision_10: 0.4500\n",
      "Epoch 138/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5879 - accuracy: 0.6865 - precision_10: 0.7547 - val_loss: 4.4872 - val_accuracy: 0.6529 - val_precision_10: 0.3690\n",
      "Epoch 139/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5854 - accuracy: 0.6905 - precision_10: 0.7133 - val_loss: 9.1313 - val_accuracy: 0.6482 - val_precision_10: 0.3871\n",
      "Epoch 140/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5876 - accuracy: 0.6891 - precision_10: 0.6734 - val_loss: 4.5653 - val_accuracy: 0.6656 - val_precision_10: 0.4167\n",
      "Epoch 141/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5857 - accuracy: 0.6921 - precision_10: 0.7411 - val_loss: 3.3222 - val_accuracy: 0.6585 - val_precision_10: 0.4074\n",
      "Epoch 142/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5858 - accuracy: 0.6939 - precision_10: 0.7509 - val_loss: 2.8881 - val_accuracy: 0.6640 - val_precision_10: 0.4091\n",
      "Epoch 143/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5838 - accuracy: 0.6913 - precision_10: 0.7973 - val_loss: 5.7838 - val_accuracy: 0.6616 - val_precision_10: 0.4179\n",
      "Epoch 144/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5944 - accuracy: 0.6921 - precision_10: 0.7857 - val_loss: 5.9004 - val_accuracy: 0.6577 - val_precision_10: 0.4167\n",
      "Epoch 145/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5850 - accuracy: 0.6933 - precision_10: 0.7305 - val_loss: 5.5908 - val_accuracy: 0.6688 - val_precision_10: 0.4808\n",
      "Epoch 146/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5898 - accuracy: 0.6909 - precision_10: 0.7519 - val_loss: 2.7803 - val_accuracy: 0.6632 - val_precision_10: 0.4118\n",
      "Epoch 147/500\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.5907 - accuracy: 0.6881 - precision_10: 0.7685 - val_loss: 9.8463 - val_accuracy: 0.6569 - val_precision_10: 0.3896\n",
      "Epoch 148/500\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.5826 - accuracy: 0.6915 - precision_10: 0.7152 - val_loss: 8.2108 - val_accuracy: 0.6601 - val_precision_10: 0.3968\n",
      "Epoch 149/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5874 - accuracy: 0.6875 - precision_10: 0.7132 - val_loss: 4.2693 - val_accuracy: 0.6474 - val_precision_10: 0.3592\n",
      "Epoch 150/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5904 - accuracy: 0.6869 - precision_10: 0.7477 - val_loss: 6.6448 - val_accuracy: 0.6593 - val_precision_10: 0.3871\n",
      "Epoch 151/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5803 - accuracy: 0.6929 - precision_10: 0.7431 - val_loss: 6.4430 - val_accuracy: 0.6450 - val_precision_10: 0.3824\n",
      "Epoch 152/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5835 - accuracy: 0.6947 - precision_10: 0.7321 - val_loss: 4.6564 - val_accuracy: 0.6482 - val_precision_10: 0.3478\n",
      "Epoch 153/500\n",
      "316/316 [==============================] - 12s 38ms/step - loss: 0.5849 - accuracy: 0.6927 - precision_10: 0.7264 - val_loss: 24.0691 - val_accuracy: 0.6585 - val_precision_10: 0.3846\n",
      "Epoch 154/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.5799 - accuracy: 0.6905 - precision_10: 0.6576 - val_loss: 13.8968 - val_accuracy: 0.6656 - val_precision_10: 0.4375\n",
      "Epoch 155/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5797 - accuracy: 0.6933 - precision_10: 0.6849 - val_loss: 22.0807 - val_accuracy: 0.6569 - val_precision_10: 0.3836\n",
      "Epoch 156/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5818 - accuracy: 0.6953 - precision_10: 0.7021 - val_loss: 14.1835 - val_accuracy: 0.6410 - val_precision_10: 0.3520\n",
      "Epoch 157/500\n",
      "316/316 [==============================] - 12s 39ms/step - loss: 0.5890 - accuracy: 0.6927 - precision_10: 0.7014 - val_loss: 7.1732 - val_accuracy: 0.6585 - val_precision_10: 0.3729\n",
      "Epoch 158/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5890 - accuracy: 0.6919 - precision_10: 0.7473 - val_loss: 2.9724 - val_accuracy: 0.6672 - val_precision_10: 0.4583\n",
      "Epoch 159/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5824 - accuracy: 0.6923 - precision_10: 0.7246 - val_loss: 7.0909 - val_accuracy: 0.6616 - val_precision_10: 0.4267\n",
      "Epoch 160/500\n",
      "316/316 [==============================] - 12s 38ms/step - loss: 0.5777 - accuracy: 0.6970 - precision_10: 0.7048 - val_loss: 7.5016 - val_accuracy: 0.6521 - val_precision_10: 0.4184\n",
      "Epoch 161/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5914 - accuracy: 0.6941 - precision_10: 0.7098 - val_loss: 3.3497 - val_accuracy: 0.6696 - val_precision_10: 0.4800\n",
      "Epoch 162/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5874 - accuracy: 0.6879 - precision_10: 0.7919 - val_loss: 3.1360 - val_accuracy: 0.6529 - val_precision_10: 0.3590\n",
      "Epoch 163/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5892 - accuracy: 0.6941 - precision_10: 0.7992 - val_loss: 7.1406 - val_accuracy: 0.6640 - val_precision_10: 0.4259\n",
      "Epoch 164/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5793 - accuracy: 0.6947 - precision_10: 0.7543 - val_loss: 5.5219 - val_accuracy: 0.6553 - val_precision_10: 0.3933\n",
      "Epoch 165/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5755 - accuracy: 0.6980 - precision_10: 0.7441 - val_loss: 12.2684 - val_accuracy: 0.6585 - val_precision_10: 0.3944\n",
      "Epoch 166/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5725 - accuracy: 0.6992 - precision_10: 0.7500 - val_loss: 13.9645 - val_accuracy: 0.6569 - val_precision_10: 0.4086\n",
      "Epoch 167/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5714 - accuracy: 0.6986 - precision_10: 0.7493 - val_loss: 13.0009 - val_accuracy: 0.6609 - val_precision_10: 0.3889\n",
      "Epoch 168/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5787 - accuracy: 0.6951 - precision_10: 0.7428 - val_loss: 13.0899 - val_accuracy: 0.6640 - val_precision_10: 0.4286\n",
      "Epoch 169/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5763 - accuracy: 0.6949 - precision_10: 0.8205 - val_loss: 8.8221 - val_accuracy: 0.6656 - val_precision_10: 0.4500\n",
      "Epoch 170/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5925 - accuracy: 0.6895 - precision_10: 0.7412 - val_loss: 11.5498 - val_accuracy: 0.6624 - val_precision_10: 0.4138\n",
      "Epoch 171/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.7096 - accuracy: 0.6869 - precision_10: 0.7957 - val_loss: 12.1165 - val_accuracy: 0.6601 - val_precision_10: 0.4381\n",
      "Epoch 172/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5942 - accuracy: 0.6915 - precision_10: 0.6997 - val_loss: 12.5135 - val_accuracy: 0.6632 - val_precision_10: 0.4579\n",
      "Epoch 173/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5865 - accuracy: 0.6907 - precision_10: 0.6827 - val_loss: 12.1115 - val_accuracy: 0.6537 - val_precision_10: 0.4413\n",
      "Epoch 174/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5778 - accuracy: 0.6953 - precision_10: 0.6910 - val_loss: 20.8090 - val_accuracy: 0.6609 - val_precision_10: 0.4167\n",
      "Epoch 175/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5820 - accuracy: 0.6941 - precision_10: 0.7267 - val_loss: 21.0574 - val_accuracy: 0.6609 - val_precision_10: 0.4000\n",
      "Epoch 176/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5817 - accuracy: 0.6955 - precision_10: 0.7476 - val_loss: 14.1138 - val_accuracy: 0.6569 - val_precision_10: 0.3692\n",
      "Epoch 177/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5751 - accuracy: 0.6947 - precision_10: 0.7135 - val_loss: 17.0748 - val_accuracy: 0.6529 - val_precision_10: 0.4018\n",
      "Epoch 178/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5750 - accuracy: 0.6992 - precision_10: 0.7416 - val_loss: 19.4634 - val_accuracy: 0.6585 - val_precision_10: 0.3846\n",
      "Epoch 179/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5786 - accuracy: 0.6955 - precision_10: 0.7155 - val_loss: 9.7520 - val_accuracy: 0.6577 - val_precision_10: 0.4452\n",
      "Epoch 180/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5713 - accuracy: 0.7024 - precision_10: 0.6983 - val_loss: 10.6901 - val_accuracy: 0.6632 - val_precision_10: 0.4000\n",
      "Epoch 181/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5714 - accuracy: 0.7008 - precision_10: 0.7432 - val_loss: 8.4007 - val_accuracy: 0.6577 - val_precision_10: 0.3974\n",
      "Epoch 182/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5799 - accuracy: 0.6925 - precision_10: 0.8416 - val_loss: 16.1560 - val_accuracy: 0.6585 - val_precision_10: 0.3770\n",
      "Epoch 183/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5816 - accuracy: 0.6863 - precision_10: 0.7923 - val_loss: 27.5482 - val_accuracy: 0.6482 - val_precision_10: 0.3372\n",
      "Epoch 184/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5803 - accuracy: 0.6923 - precision_10: 0.7473 - val_loss: 20.9415 - val_accuracy: 0.6537 - val_precision_10: 0.3918\n",
      "Epoch 185/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5839 - accuracy: 0.6923 - precision_10: 0.7546 - val_loss: 19.8299 - val_accuracy: 0.6593 - val_precision_10: 0.3871\n",
      "Epoch 186/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 2.2813 - accuracy: 0.6955 - precision_10: 0.7703 - val_loss: 1.3911 - val_accuracy: 0.6601 - val_precision_10: 0.3968\n",
      "Epoch 187/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5809 - accuracy: 0.6974 - precision_10: 0.7672 - val_loss: 2.3433 - val_accuracy: 0.6624 - val_precision_10: 0.4219\n",
      "Epoch 188/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5743 - accuracy: 0.7004 - precision_10: 0.7649 - val_loss: 3.4298 - val_accuracy: 0.6616 - val_precision_10: 0.4267\n",
      "Epoch 189/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5696 - accuracy: 0.7032 - precision_10: 0.7892 - val_loss: 3.3646 - val_accuracy: 0.6585 - val_precision_10: 0.4286\n",
      "Epoch 190/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5764 - accuracy: 0.7032 - precision_10: 0.7500 - val_loss: 3.1440 - val_accuracy: 0.6601 - val_precision_10: 0.3673\n",
      "Epoch 191/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5707 - accuracy: 0.7004 - precision_10: 0.8371 - val_loss: 2.9755 - val_accuracy: 0.6537 - val_precision_10: 0.3735\n",
      "Epoch 192/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5651 - accuracy: 0.7038 - precision_10: 0.7431 - val_loss: 6.0651 - val_accuracy: 0.6395 - val_precision_10: 0.3415\n",
      "Epoch 193/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.5673 - accuracy: 0.7032 - precision_10: 0.7667 - val_loss: 4.2181 - val_accuracy: 0.6529 - val_precision_10: 0.3625\n",
      "Epoch 194/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5630 - accuracy: 0.7068 - precision_10: 0.7823 - val_loss: 5.5325 - val_accuracy: 0.6521 - val_precision_10: 0.3678\n",
      "Epoch 195/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5629 - accuracy: 0.7058 - precision_10: 0.7621 - val_loss: 5.2563 - val_accuracy: 0.6545 - val_precision_10: 0.3485\n",
      "Epoch 196/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.5645 - accuracy: 0.7040 - precision_10: 0.7475 - val_loss: 6.0572 - val_accuracy: 0.6537 - val_precision_10: 0.3960\n",
      "Epoch 197/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5587 - accuracy: 0.7064 - precision_10: 0.7476 - val_loss: 7.6252 - val_accuracy: 0.6577 - val_precision_10: 0.3857\n",
      "Epoch 198/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5620 - accuracy: 0.7054 - precision_10: 0.8306 - val_loss: 7.3631 - val_accuracy: 0.6577 - val_precision_10: 0.3788\n",
      "Epoch 199/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5725 - accuracy: 0.7026 - precision_10: 0.8058 - val_loss: 5.3236 - val_accuracy: 0.6498 - val_precision_10: 0.3587\n",
      "Epoch 200/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5629 - accuracy: 0.7068 - precision_10: 0.7500 - val_loss: 4.7210 - val_accuracy: 0.6529 - val_precision_10: 0.4141\n",
      "Epoch 201/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5658 - accuracy: 0.7072 - precision_10: 0.7804 - val_loss: 4.5987 - val_accuracy: 0.6585 - val_precision_10: 0.3810\n",
      "Epoch 202/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5907 - accuracy: 0.7075 - precision_10: 0.8429 - val_loss: 5.1238 - val_accuracy: 0.6593 - val_precision_10: 0.3939\n",
      "Epoch 203/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.6119 - accuracy: 0.6945 - precision_10: 0.8592 - val_loss: 3.5399 - val_accuracy: 0.6624 - val_precision_10: 0.4138\n",
      "Epoch 204/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 1.4248 - accuracy: 0.6982 - precision_10: 0.7634 - val_loss: 1.1835 - val_accuracy: 0.6688 - val_precision_10: 0.4688\n",
      "Epoch 205/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.6775 - accuracy: 0.6994 - precision_10: 0.8145 - val_loss: 3.5808 - val_accuracy: 0.6545 - val_precision_10: 0.3718\n",
      "Epoch 206/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5660 - accuracy: 0.7018 - precision_10: 0.7403 - val_loss: 4.5373 - val_accuracy: 0.6498 - val_precision_10: 0.3415\n",
      "Epoch 207/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5644 - accuracy: 0.7101 - precision_10: 0.7585 - val_loss: 4.2622 - val_accuracy: 0.6553 - val_precision_10: 0.3827\n",
      "Epoch 208/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5624 - accuracy: 0.7085 - precision_10: 0.7859 - val_loss: 5.4457 - val_accuracy: 0.6482 - val_precision_10: 0.3571\n",
      "Epoch 209/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5565 - accuracy: 0.7111 - precision_10: 0.7447 - val_loss: 4.6535 - val_accuracy: 0.6537 - val_precision_10: 0.3846\n",
      "Epoch 210/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5599 - accuracy: 0.7087 - precision_10: 0.7607 - val_loss: 7.0045 - val_accuracy: 0.6537 - val_precision_10: 0.3895\n",
      "Epoch 211/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5673 - accuracy: 0.7016 - precision_10: 0.7771 - val_loss: 4.9506 - val_accuracy: 0.6537 - val_precision_10: 0.3820\n",
      "Epoch 212/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5575 - accuracy: 0.7107 - precision_10: 0.8026 - val_loss: 7.3903 - val_accuracy: 0.6513 - val_precision_10: 0.4155\n",
      "Epoch 213/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5623 - accuracy: 0.7064 - precision_10: 0.7640 - val_loss: 2.9140 - val_accuracy: 0.6601 - val_precision_10: 0.3898\n",
      "Epoch 214/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5624 - accuracy: 0.7077 - precision_10: 0.7667 - val_loss: 3.5750 - val_accuracy: 0.6545 - val_precision_10: 0.3438\n",
      "Epoch 215/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5567 - accuracy: 0.7087 - precision_10: 0.7957 - val_loss: 5.0807 - val_accuracy: 0.6553 - val_precision_10: 0.3582\n",
      "Epoch 216/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5707 - accuracy: 0.7068 - precision_10: 0.7823 - val_loss: 4.2664 - val_accuracy: 0.6569 - val_precision_10: 0.4066\n",
      "Epoch 217/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5619 - accuracy: 0.7034 - precision_10: 0.7468 - val_loss: 4.9626 - val_accuracy: 0.6490 - val_precision_10: 0.3548\n",
      "Epoch 218/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5737 - accuracy: 0.7064 - precision_10: 0.7708 - val_loss: 2.9218 - val_accuracy: 0.6529 - val_precision_10: 0.3721\n",
      "Epoch 219/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5609 - accuracy: 0.7081 - precision_10: 0.7818 - val_loss: 3.4776 - val_accuracy: 0.6545 - val_precision_10: 0.3936\n",
      "Epoch 220/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5678 - accuracy: 0.7058 - precision_10: 0.8233 - val_loss: 2.7106 - val_accuracy: 0.6537 - val_precision_10: 0.3478\n",
      "Epoch 221/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5649 - accuracy: 0.7046 - precision_10: 0.7772 - val_loss: 3.1853 - val_accuracy: 0.6585 - val_precision_10: 0.3944\n",
      "Epoch 222/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5610 - accuracy: 0.7077 - precision_10: 0.7616 - val_loss: 3.0169 - val_accuracy: 0.6498 - val_precision_10: 0.3725\n",
      "Epoch 223/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5600 - accuracy: 0.7089 - precision_10: 0.7625 - val_loss: 4.0109 - val_accuracy: 0.6498 - val_precision_10: 0.3289\n",
      "Epoch 224/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5580 - accuracy: 0.7070 - precision_10: 0.7712 - val_loss: 4.3429 - val_accuracy: 0.6561 - val_precision_10: 0.3594\n",
      "Epoch 225/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5596 - accuracy: 0.7087 - precision_10: 0.8143 - val_loss: 4.2559 - val_accuracy: 0.6490 - val_precision_10: 0.3689\n",
      "Epoch 226/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5832 - accuracy: 0.7040 - precision_10: 0.8121 - val_loss: 1.7289 - val_accuracy: 0.6553 - val_precision_10: 0.3908\n",
      "Epoch 227/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5614 - accuracy: 0.7099 - precision_10: 0.7927 - val_loss: 2.9155 - val_accuracy: 0.6624 - val_precision_10: 0.3958\n",
      "Epoch 228/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5630 - accuracy: 0.7101 - precision_10: 0.8144 - val_loss: 3.0519 - val_accuracy: 0.6490 - val_precision_10: 0.3579\n",
      "Epoch 229/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5540 - accuracy: 0.7070 - precision_10: 0.7381 - val_loss: 3.5318 - val_accuracy: 0.6506 - val_precision_10: 0.3711\n",
      "Epoch 230/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5572 - accuracy: 0.7089 - precision_10: 0.7841 - val_loss: 3.9531 - val_accuracy: 0.6506 - val_precision_10: 0.3762\n",
      "Epoch 231/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5570 - accuracy: 0.7097 - precision_10: 0.7528 - val_loss: 2.3954 - val_accuracy: 0.6529 - val_precision_10: 0.3721\n",
      "Epoch 232/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5577 - accuracy: 0.7119 - precision_10: 0.8224 - val_loss: 3.2934 - val_accuracy: 0.6545 - val_precision_10: 0.3750\n",
      "Epoch 233/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5660 - accuracy: 0.7066 - precision_10: 0.7714 - val_loss: 4.8324 - val_accuracy: 0.6537 - val_precision_10: 0.3636\n",
      "Epoch 234/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5509 - accuracy: 0.7117 - precision_10: 0.7538 - val_loss: 7.0434 - val_accuracy: 0.6521 - val_precision_10: 0.4017\n",
      "Epoch 235/500\n",
      "316/316 [==============================] - 11s 33ms/step - loss: 0.5559 - accuracy: 0.7105 - precision_10: 0.7608 - val_loss: 6.0511 - val_accuracy: 0.6601 - val_precision_10: 0.3934\n",
      "Epoch 236/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5582 - accuracy: 0.7095 - precision_10: 0.7692 - val_loss: 5.3402 - val_accuracy: 0.6490 - val_precision_10: 0.4229\n",
      "Epoch 237/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5593 - accuracy: 0.7093 - precision_10: 0.7927 - val_loss: 5.7296 - val_accuracy: 0.6569 - val_precision_10: 0.3896\n",
      "Epoch 238/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5543 - accuracy: 0.7105 - precision_10: 0.7421 - val_loss: 7.2669 - val_accuracy: 0.6561 - val_precision_10: 0.3846\n",
      "Epoch 239/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5589 - accuracy: 0.7070 - precision_10: 0.7740 - val_loss: 6.3428 - val_accuracy: 0.6577 - val_precision_10: 0.4111\n",
      "Epoch 240/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5661 - accuracy: 0.7028 - precision_10: 0.7896 - val_loss: 5.6910 - val_accuracy: 0.6490 - val_precision_10: 0.4246\n",
      "Epoch 241/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5743 - accuracy: 0.7056 - precision_10: 0.7170 - val_loss: 4.1960 - val_accuracy: 0.6498 - val_precision_10: 0.4226\n",
      "Epoch 242/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5677 - accuracy: 0.7070 - precision_10: 0.8328 - val_loss: 2.4567 - val_accuracy: 0.6577 - val_precision_10: 0.3824\n",
      "Epoch 243/500\n",
      "316/316 [==============================] - 12s 37ms/step - loss: 0.5603 - accuracy: 0.7072 - precision_10: 0.8136 - val_loss: 2.8439 - val_accuracy: 0.6537 - val_precision_10: 0.3735\n",
      "Epoch 244/500\n",
      "316/316 [==============================] - 12s 39ms/step - loss: 0.5559 - accuracy: 0.7103 - precision_10: 0.8132 - val_loss: 2.6623 - val_accuracy: 0.6632 - val_precision_10: 0.4328\n",
      "Epoch 245/500\n",
      "316/316 [==============================] - 13s 40ms/step - loss: 0.5601 - accuracy: 0.7072 - precision_10: 0.7819 - val_loss: 4.6285 - val_accuracy: 0.6561 - val_precision_10: 0.4516\n",
      "Epoch 246/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5904 - accuracy: 0.6992 - precision_10: 0.7905 - val_loss: 1.8300 - val_accuracy: 0.6593 - val_precision_10: 0.4079\n",
      "Epoch 247/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.5681 - accuracy: 0.7034 - precision_10: 0.7688 - val_loss: 4.8790 - val_accuracy: 0.6545 - val_precision_10: 0.3864\n",
      "Epoch 248/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5807 - accuracy: 0.7046 - precision_10: 0.7953 - val_loss: 2.1697 - val_accuracy: 0.6482 - val_precision_10: 0.4054\n",
      "Epoch 249/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5592 - accuracy: 0.7074 - precision_10: 0.7656 - val_loss: 4.6858 - val_accuracy: 0.6498 - val_precision_10: 0.3333\n",
      "Epoch 250/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5589 - accuracy: 0.7087 - precision_10: 0.7821 - val_loss: 4.8737 - val_accuracy: 0.6442 - val_precision_10: 0.3778\n",
      "Epoch 251/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5574 - accuracy: 0.7064 - precision_10: 0.7488 - val_loss: 5.9516 - val_accuracy: 0.6593 - val_precision_10: 0.4079\n",
      "Epoch 252/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5559 - accuracy: 0.7024 - precision_10: 0.7017 - val_loss: 8.0249 - val_accuracy: 0.6577 - val_precision_10: 0.4412\n",
      "Epoch 253/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5523 - accuracy: 0.7121 - precision_10: 0.7955 - val_loss: 7.7733 - val_accuracy: 0.6482 - val_precision_10: 0.3654\n",
      "Epoch 254/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5557 - accuracy: 0.7115 - precision_10: 0.7659 - val_loss: 3.8632 - val_accuracy: 0.6537 - val_precision_10: 0.4037\n",
      "Epoch 255/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5530 - accuracy: 0.7109 - precision_10: 0.7296 - val_loss: 6.6311 - val_accuracy: 0.6513 - val_precision_10: 0.3723\n",
      "Epoch 256/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5590 - accuracy: 0.7127 - precision_10: 0.7521 - val_loss: 8.6880 - val_accuracy: 0.6521 - val_precision_10: 0.3838\n",
      "Epoch 257/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5648 - accuracy: 0.7079 - precision_10: 0.7784 - val_loss: 9.2833 - val_accuracy: 0.6545 - val_precision_10: 0.3810\n",
      "Epoch 258/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5623 - accuracy: 0.7072 - precision_10: 0.7387 - val_loss: 15.9188 - val_accuracy: 0.6577 - val_precision_10: 0.3889\n",
      "Epoch 259/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5592 - accuracy: 0.7070 - precision_10: 0.7392 - val_loss: 16.3623 - val_accuracy: 0.6426 - val_precision_10: 0.3600\n",
      "Epoch 260/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 1.4840 - accuracy: 0.7129 - precision_10: 0.7474 - val_loss: 4.8097 - val_accuracy: 0.6513 - val_precision_10: 0.4341\n",
      "Epoch 261/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.8790 - accuracy: 0.7131 - precision_10: 0.7065 - val_loss: 4.9861 - val_accuracy: 0.6545 - val_precision_10: 0.4057\n",
      "Epoch 262/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5617 - accuracy: 0.7111 - precision_10: 0.7710 - val_loss: 4.2667 - val_accuracy: 0.6601 - val_precision_10: 0.3968\n",
      "Epoch 263/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5489 - accuracy: 0.7133 - precision_10: 0.8311 - val_loss: 7.7092 - val_accuracy: 0.6506 - val_precision_10: 0.3626\n",
      "Epoch 264/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5568 - accuracy: 0.7111 - precision_10: 0.7578 - val_loss: 7.3237 - val_accuracy: 0.6585 - val_precision_10: 0.4026\n",
      "Epoch 265/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5522 - accuracy: 0.7125 - precision_10: 0.8120 - val_loss: 5.9301 - val_accuracy: 0.6545 - val_precision_10: 0.3780\n",
      "Epoch 266/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.5438 - accuracy: 0.7165 - precision_10: 0.8182 - val_loss: 10.1836 - val_accuracy: 0.6537 - val_precision_10: 0.3981\n",
      "Epoch 267/500\n",
      "316/316 [==============================] - 11s 34ms/step - loss: 0.5498 - accuracy: 0.7145 - precision_10: 0.8217 - val_loss: 6.9032 - val_accuracy: 0.6616 - val_precision_10: 0.4353\n",
      "Epoch 268/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5479 - accuracy: 0.7133 - precision_10: 0.7886 - val_loss: 5.3602 - val_accuracy: 0.6616 - val_precision_10: 0.4247\n",
      "Epoch 269/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5537 - accuracy: 0.7077 - precision_10: 0.7578 - val_loss: 4.5327 - val_accuracy: 0.6498 - val_precision_10: 0.3774\n",
      "Epoch 270/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 2.0321 - accuracy: 0.7115 - precision_10: 0.7840 - val_loss: 6.8018 - val_accuracy: 0.6466 - val_precision_10: 0.3438\n",
      "Epoch 271/500\n",
      "316/316 [==============================] - 11s 35ms/step - loss: 0.7330 - accuracy: 0.7095 - precision_10: 0.7745 - val_loss: 8.6263 - val_accuracy: 0.6513 - val_precision_10: 0.3929\n",
      "Epoch 272/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5648 - accuracy: 0.7145 - precision_10: 0.7515 - val_loss: 15.7969 - val_accuracy: 0.6529 - val_precision_10: 0.4179\n",
      "Epoch 273/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5784 - accuracy: 0.7119 - precision_10: 0.7634 - val_loss: 13.0618 - val_accuracy: 0.6466 - val_precision_10: 0.4096\n",
      "Epoch 274/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5877 - accuracy: 0.7119 - precision_10: 0.7682 - val_loss: 10.9584 - val_accuracy: 0.6545 - val_precision_10: 0.3611\n",
      "Epoch 275/500\n",
      "316/316 [==============================] - 10s 31ms/step - loss: 0.5504 - accuracy: 0.7133 - precision_10: 0.7942 - val_loss: 18.7475 - val_accuracy: 0.6553 - val_precision_10: 0.4128\n",
      "Epoch 276/500\n",
      "316/316 [==============================] - 10s 33ms/step - loss: 0.5454 - accuracy: 0.7155 - precision_10: 0.7913 - val_loss: 17.3519 - val_accuracy: 0.6545 - val_precision_10: 0.4107\n",
      "Epoch 277/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5646 - accuracy: 0.7113 - precision_10: 0.7618 - val_loss: 14.4192 - val_accuracy: 0.6521 - val_precision_10: 0.3838\n",
      "Epoch 278/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5456 - accuracy: 0.7129 - precision_10: 0.8082 - val_loss: 22.1184 - val_accuracy: 0.6537 - val_precision_10: 0.3820\n",
      "Epoch 279/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5462 - accuracy: 0.7131 - precision_10: 0.7801 - val_loss: 17.1600 - val_accuracy: 0.6593 - val_precision_10: 0.4453\n",
      "Epoch 280/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5439 - accuracy: 0.7141 - precision_10: 0.7775 - val_loss: 21.6904 - val_accuracy: 0.6553 - val_precision_10: 0.4112\n",
      "Epoch 281/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5415 - accuracy: 0.7153 - precision_10: 0.7709 - val_loss: 22.0180 - val_accuracy: 0.6545 - val_precision_10: 0.4206\n",
      "Epoch 282/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5431 - accuracy: 0.7147 - precision_10: 0.7828 - val_loss: 23.3194 - val_accuracy: 0.6561 - val_precision_10: 0.4237\n",
      "Epoch 283/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5637 - accuracy: 0.7171 - precision_10: 0.8259 - val_loss: 13.9843 - val_accuracy: 0.6553 - val_precision_10: 0.4128\n",
      "Epoch 284/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5543 - accuracy: 0.7121 - precision_10: 0.7749 - val_loss: 17.7092 - val_accuracy: 0.6585 - val_precision_10: 0.4286\n",
      "Epoch 285/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5584 - accuracy: 0.7151 - precision_10: 0.7582 - val_loss: 5.4680 - val_accuracy: 0.6585 - val_precision_10: 0.4138\n",
      "Epoch 286/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5629 - accuracy: 0.7077 - precision_10: 0.8328 - val_loss: 10.6314 - val_accuracy: 0.6553 - val_precision_10: 0.3662\n",
      "Epoch 287/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5489 - accuracy: 0.7147 - precision_10: 0.8272 - val_loss: 14.8277 - val_accuracy: 0.6513 - val_precision_10: 0.4091\n",
      "Epoch 288/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5448 - accuracy: 0.7171 - precision_10: 0.8195 - val_loss: 25.2070 - val_accuracy: 0.6529 - val_precision_10: 0.4179\n",
      "Epoch 289/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5463 - accuracy: 0.7119 - precision_10: 0.7770 - val_loss: 16.4295 - val_accuracy: 0.6521 - val_precision_10: 0.3708cy: 0.7116 - precision_10: \n",
      "Epoch 290/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5431 - accuracy: 0.7161 - precision_10: 0.7575 - val_loss: 18.8132 - val_accuracy: 0.6498 - val_precision_10: 0.3968\n",
      "Epoch 291/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5563 - accuracy: 0.7155 - precision_10: 0.7822 - val_loss: 9.0025 - val_accuracy: 0.6593 - val_precision_10: 0.3542\n",
      "Epoch 292/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5577 - accuracy: 0.7093 - precision_10: 0.8309 - val_loss: 11.5952 - val_accuracy: 0.6561 - val_precision_10: 0.4338\n",
      "Epoch 293/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5406 - accuracy: 0.7206 - precision_10: 0.7929 - val_loss: 12.8705 - val_accuracy: 0.6577 - val_precision_10: 0.4344\n",
      "Epoch 294/500\n",
      "316/316 [==============================] - 7s 22ms/step - loss: 0.5457 - accuracy: 0.7177 - precision_10: 0.7486 - val_loss: 14.9036 - val_accuracy: 0.6569 - val_precision_10: 0.3836\n",
      "Epoch 295/500\n",
      "316/316 [==============================] - 7s 23ms/step - loss: 0.5455 - accuracy: 0.7169 - precision_10: 0.8042 - val_loss: 14.3985 - val_accuracy: 0.6513 - val_precision_10: 0.4333\n",
      "Epoch 296/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5402 - accuracy: 0.7177 - precision_10: 0.7688 - val_loss: 13.6327 - val_accuracy: 0.6434 - val_precision_10: 0.3455\n",
      "Epoch 297/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5499 - accuracy: 0.7141 - precision_10: 0.7933 - val_loss: 9.8537 - val_accuracy: 0.6521 - val_precision_10: 0.3678\n",
      "Epoch 298/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5392 - accuracy: 0.7151 - precision_10: 0.7917 - val_loss: 12.9998 - val_accuracy: 0.6585 - val_precision_10: 0.4118\n",
      "Epoch 299/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5386 - accuracy: 0.7153 - precision_10: 0.7744 - val_loss: 14.5502 - val_accuracy: 0.6521 - val_precision_10: 0.4173\n",
      "Epoch 300/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5312 - accuracy: 0.7206 - precision_10: 0.8057 - val_loss: 22.8166 - val_accuracy: 0.6561 - val_precision_10: 0.4118\n",
      "Epoch 301/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5407 - accuracy: 0.7167 - precision_10: 0.7863 - val_loss: 12.3578 - val_accuracy: 0.6537 - val_precision_10: 0.3918\n",
      "Epoch 302/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5402 - accuracy: 0.7200 - precision_10: 0.8259 - val_loss: 42.0715 - val_accuracy: 0.6561 - val_precision_10: 0.4167\n",
      "Epoch 303/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5667 - accuracy: 0.7068 - precision_10: 0.7638 - val_loss: 19.0091 - val_accuracy: 0.6569 - val_precision_10: 0.4380\n",
      "Epoch 304/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5463 - accuracy: 0.7143 - precision_10: 0.7605 - val_loss: 22.6301 - val_accuracy: 0.6601 - val_precision_10: 0.4591\n",
      "Epoch 305/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5344 - accuracy: 0.7200 - precision_10: 0.7809 - val_loss: 28.9478 - val_accuracy: 0.6490 - val_precision_10: 0.3846\n",
      "Epoch 306/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5486 - accuracy: 0.7165 - precision_10: 0.7950 - val_loss: 17.0710 - val_accuracy: 0.6569 - val_precision_10: 0.4331\n",
      "Epoch 307/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5358 - accuracy: 0.7218 - precision_10: 0.8043 - val_loss: 27.0791 - val_accuracy: 0.6553 - val_precision_10: 0.4228\n",
      "Epoch 308/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5340 - accuracy: 0.7182 - precision_10: 0.7913 - val_loss: 32.1249 - val_accuracy: 0.6601 - val_precision_10: 0.4235\n",
      "Epoch 309/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5488 - accuracy: 0.7173 - precision_10: 0.7780 - val_loss: 27.8328 - val_accuracy: 0.6577 - val_precision_10: 0.4184\n",
      "Epoch 310/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5479 - accuracy: 0.7186 - precision_10: 0.7948 - val_loss: 16.0315 - val_accuracy: 0.6577 - val_precision_10: 0.3974\n",
      "Epoch 311/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5343 - accuracy: 0.7206 - precision_10: 0.8097 - val_loss: 25.4688 - val_accuracy: 0.6593 - val_precision_10: 0.4286\n",
      "Epoch 312/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5371 - accuracy: 0.7192 - precision_10: 0.8054 - val_loss: 23.5555 - val_accuracy: 0.6537 - val_precision_10: 0.4037\n",
      "Epoch 313/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5435 - accuracy: 0.7212 - precision_10: 0.8410 - val_loss: 14.4597 - val_accuracy: 0.6577 - val_precision_10: 0.4286\n",
      "Epoch 314/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5409 - accuracy: 0.7194 - precision_10: 0.8058 - val_loss: 11.0584 - val_accuracy: 0.6553 - val_precision_10: 0.3908\n",
      "Epoch 315/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5373 - accuracy: 0.7208 - precision_10: 0.8115 - val_loss: 6.6724 - val_accuracy: 0.6585 - val_precision_10: 0.4000\n",
      "Epoch 316/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5364 - accuracy: 0.7167 - precision_10: 0.7928 - val_loss: 10.9417 - val_accuracy: 0.6664 - val_precision_10: 0.4850\n",
      "Epoch 317/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5374 - accuracy: 0.7179 - precision_10: 0.7969 - val_loss: 17.9934 - val_accuracy: 0.6569 - val_precision_10: 0.4351\n",
      "Epoch 318/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5394 - accuracy: 0.7165 - precision_10: 0.8033 - val_loss: 15.6255 - val_accuracy: 0.6561 - val_precision_10: 0.4100\n",
      "Epoch 319/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5455 - accuracy: 0.7153 - precision_10: 0.8078 - val_loss: 13.7869 - val_accuracy: 0.6601 - val_precision_10: 0.4564\n",
      "Epoch 320/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5378 - accuracy: 0.7204 - precision_10: 0.8222 - val_loss: 13.8733 - val_accuracy: 0.6537 - val_precision_10: 0.4087\n",
      "Epoch 321/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5336 - accuracy: 0.7214 - precision_10: 0.7817 - val_loss: 17.3665 - val_accuracy: 0.6624 - val_precision_10: 0.4537\n",
      "Epoch 322/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5424 - accuracy: 0.7173 - precision_10: 0.7865 - val_loss: 14.3271 - val_accuracy: 0.6529 - val_precision_10: 0.3962\n",
      "Epoch 323/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5452 - accuracy: 0.7184 - precision_10: 0.7717 - val_loss: 75.1643 - val_accuracy: 0.6561 - val_precision_10: 0.4062\n",
      "Epoch 324/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5332 - accuracy: 0.7190 - precision_10: 0.7845 - val_loss: 60.8888 - val_accuracy: 0.6616 - val_precision_10: 0.4444\n",
      "Epoch 325/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 1.5900 - accuracy: 0.7149 - precision_10: 0.8659 - val_loss: 5.6284 - val_accuracy: 0.6616 - val_precision_10: 0.4530\n",
      "Epoch 326/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5507 - accuracy: 0.7151 - precision_10: 0.8103 - val_loss: 8.8215 - val_accuracy: 0.6624 - val_precision_10: 0.4375\n",
      "Epoch 327/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5453 - accuracy: 0.7157 - precision_10: 0.7684 - val_loss: 8.8743 - val_accuracy: 0.6593 - val_precision_10: 0.4286\n",
      "Epoch 328/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5364 - accuracy: 0.7184 - precision_10: 0.7880 - val_loss: 9.9197 - val_accuracy: 0.6648 - val_precision_10: 0.4793\n",
      "Epoch 329/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5364 - accuracy: 0.7149 - precision_10: 0.7485 - val_loss: 8.3930 - val_accuracy: 0.6537 - val_precision_10: 0.4054\n",
      "Epoch 330/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5292 - accuracy: 0.7208 - precision_10: 0.7970 - val_loss: 13.1893 - val_accuracy: 0.6506 - val_precision_10: 0.3711\n",
      "Epoch 331/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5323 - accuracy: 0.7204 - precision_10: 0.8066 - val_loss: 10.7081 - val_accuracy: 0.6561 - val_precision_10: 0.4262\n",
      "Epoch 332/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5390 - accuracy: 0.7224 - precision_10: 0.8677 - val_loss: 9.1993 - val_accuracy: 0.6585 - val_precision_10: 0.4453\n",
      "Epoch 333/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5403 - accuracy: 0.7181 - precision_10: 0.7960 - val_loss: 9.9692 - val_accuracy: 0.6624 - val_precision_10: 0.4583\n",
      "Epoch 334/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5378 - accuracy: 0.7169 - precision_10: 0.7868 - val_loss: 11.4640 - val_accuracy: 0.6561 - val_precision_10: 0.4082\n",
      "Epoch 335/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5276 - accuracy: 0.7218 - precision_10: 0.7942 - val_loss: 13.1685 - val_accuracy: 0.6529 - val_precision_10: 0.3830\n",
      "Epoch 336/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5306 - accuracy: 0.7226 - precision_10: 0.8125 - val_loss: 14.7088 - val_accuracy: 0.6616 - val_precision_10: 0.4586\n",
      "Epoch 337/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5289 - accuracy: 0.7226 - precision_10: 0.8266 - val_loss: 17.7586 - val_accuracy: 0.6593 - val_precision_10: 0.4462\n",
      "Epoch 338/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5542 - accuracy: 0.7159 - precision_10: 0.7949 - val_loss: 14.4628 - val_accuracy: 0.6537 - val_precision_10: 0.3939\n",
      "Epoch 339/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5408 - accuracy: 0.7167 - precision_10: 0.7490 - val_loss: 6.8178 - val_accuracy: 0.6482 - val_precision_10: 0.4278\n",
      "Epoch 340/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5381 - accuracy: 0.7137 - precision_10: 0.7803 - val_loss: 14.7267 - val_accuracy: 0.6577 - val_precision_10: 0.4273acy:\n",
      "Epoch 341/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5328 - accuracy: 0.7250 - precision_10: 0.8254 - val_loss: 9.5593 - val_accuracy: 0.6616 - val_precision_10: 0.4353\n",
      "Epoch 342/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5375 - accuracy: 0.7175 - precision_10: 0.8367 - val_loss: 11.3032 - val_accuracy: 0.6585 - val_precision_10: 0.4286\n",
      "Epoch 343/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5492 - accuracy: 0.7196 - precision_10: 0.8747 - val_loss: 6.2380 - val_accuracy: 0.6577 - val_precision_10: 0.4474\n",
      "Epoch 344/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5303 - accuracy: 0.7196 - precision_10: 0.7589 - val_loss: 13.7549 - val_accuracy: 0.6601 - val_precision_10: 0.4156\n",
      "Epoch 345/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5286 - accuracy: 0.7230 - precision_10: 0.8527 - val_loss: 11.9283 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 346/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5372 - accuracy: 0.7192 - precision_10: 0.8067 - val_loss: 12.1026 - val_accuracy: 0.6561 - val_precision_10: 0.4262\n",
      "Epoch 347/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5410 - accuracy: 0.7202 - precision_10: 0.8131 - val_loss: 9.6044 - val_accuracy: 0.6680 - val_precision_10: 0.4872\n",
      "Epoch 348/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5369 - accuracy: 0.7202 - precision_10: 0.7983 - val_loss: 9.6890 - val_accuracy: 0.6577 - val_precision_10: 0.4273\n",
      "Epoch 349/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5341 - accuracy: 0.7214 - precision_10: 0.8087 - val_loss: 6.2126 - val_accuracy: 0.6640 - val_precision_10: 0.4710\n",
      "Epoch 350/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5346 - accuracy: 0.7198 - precision_10: 0.8151 - val_loss: 10.8500 - val_accuracy: 0.6664 - val_precision_10: 0.4762\n",
      "Epoch 351/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5656 - accuracy: 0.7161 - precision_10: 0.8189 - val_loss: 1.9324 - val_accuracy: 0.6632 - val_precision_10: 0.4554\n",
      "Epoch 352/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.6402 - accuracy: 0.7177 - precision_10: 0.7899 - val_loss: 3.7084 - val_accuracy: 0.6609 - val_precision_10: 0.4362\n",
      "Epoch 353/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6755 - accuracy: 0.7163 - precision_10: 0.7829 - val_loss: 9.1633 - val_accuracy: 0.6537 - val_precision_10: 0.4160\n",
      "Epoch 354/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5466 - accuracy: 0.7200 - precision_10: 0.7966 - val_loss: 6.4690 - val_accuracy: 0.6609 - val_precision_10: 0.4545\n",
      "Epoch 355/500\n",
      "316/316 [==============================] - 7s 22ms/step - loss: 0.5423 - accuracy: 0.7218 - precision_10: 0.8221 - val_loss: 2.8827 - val_accuracy: 0.6616 - val_precision_10: 0.4495\n",
      "Epoch 356/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5515 - accuracy: 0.7190 - precision_10: 0.8383 - val_loss: 2.9349 - val_accuracy: 0.6640 - val_precision_10: 0.4733\n",
      "Epoch 357/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5329 - accuracy: 0.7218 - precision_10: 0.8017 - val_loss: 3.1984 - val_accuracy: 0.6616 - val_precision_10: 0.4337\n",
      "Epoch 358/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5269 - accuracy: 0.7234 - precision_10: 0.8356 - val_loss: 4.6866 - val_accuracy: 0.6609 - val_precision_10: 0.4318\n",
      "Epoch 359/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5233 - accuracy: 0.7270 - precision_10: 0.8291 - val_loss: 6.8449 - val_accuracy: 0.6569 - val_precision_10: 0.3924\n",
      "Epoch 360/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5303 - accuracy: 0.7238 - precision_10: 0.8203 - val_loss: 6.0434 - val_accuracy: 0.6553 - val_precision_10: 0.4228\n",
      "Epoch 361/500\n",
      "316/316 [==============================] - 7s 22ms/step - loss: 0.5225 - accuracy: 0.7276 - precision_10: 0.8169 - val_loss: 7.3960 - val_accuracy: 0.6521 - val_precision_10: 0.4034\n",
      "Epoch 362/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5229 - accuracy: 0.7234 - precision_10: 0.8128 - val_loss: 10.2302 - val_accuracy: 0.6601 - val_precision_10: 0.4444\n",
      "Epoch 363/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5368 - accuracy: 0.7196 - precision_10: 0.8022 - val_loss: 5.6988 - val_accuracy: 0.6616 - val_precision_10: 0.4421\n",
      "Epoch 364/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5635 - accuracy: 0.7177 - precision_10: 0.8240 - val_loss: 1.3917 - val_accuracy: 0.6593 - val_precision_10: 0.4205\n",
      "Epoch 365/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5252 - accuracy: 0.7222 - precision_10: 0.7903 - val_loss: 5.9351 - val_accuracy: 0.6569 - val_precision_10: 0.4331\n",
      "Epoch 366/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5410 - accuracy: 0.7151 - precision_10: 0.7903 - val_loss: 6.1723 - val_accuracy: 0.6593 - val_precision_10: 0.4533\n",
      "Epoch 367/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5284 - accuracy: 0.7228 - precision_10: 0.8170 - val_loss: 9.0630 - val_accuracy: 0.6616 - val_precision_10: 0.4654\n",
      "Epoch 368/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5280 - accuracy: 0.7230 - precision_10: 0.7786 - val_loss: 4.3806 - val_accuracy: 0.6672 - val_precision_10: 0.4767\n",
      "Epoch 369/500\n",
      "316/316 [==============================] - 7s 23ms/step - loss: 0.5252 - accuracy: 0.7244 - precision_10: 0.8315 - val_loss: 4.0970 - val_accuracy: 0.6577 - val_precision_10: 0.4273\n",
      "Epoch 370/500\n",
      "316/316 [==============================] - 7s 22ms/step - loss: 0.5183 - accuracy: 0.7299 - precision_10: 0.8114 - val_loss: 7.9502 - val_accuracy: 0.6537 - val_precision_10: 0.4439\n",
      "Epoch 371/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5301 - accuracy: 0.7246 - precision_10: 0.8036 - val_loss: 4.3824 - val_accuracy: 0.6561 - val_precision_10: 0.4100\n",
      "Epoch 372/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5306 - accuracy: 0.7214 - precision_10: 0.8198 - val_loss: 11.3090 - val_accuracy: 0.6609 - val_precision_10: 0.4400\n",
      "Epoch 373/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5240 - accuracy: 0.7260 - precision_10: 0.8513 - val_loss: 10.5515 - val_accuracy: 0.6640 - val_precision_10: 0.4535\n",
      "Epoch 374/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5383 - accuracy: 0.7212 - precision_10: 0.8283 - val_loss: 7.1474 - val_accuracy: 0.6601 - val_precision_10: 0.4235\n",
      "Epoch 375/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5287 - accuracy: 0.7212 - precision_10: 0.8329 - val_loss: 6.6942 - val_accuracy: 0.6616 - val_precision_10: 0.4382\n",
      "Epoch 376/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5246 - accuracy: 0.7254 - precision_10: 0.8535 - val_loss: 8.0770 - val_accuracy: 0.6632 - val_precision_10: 0.4662\n",
      "Epoch 377/500\n",
      "316/316 [==============================] - 7s 24ms/step - loss: 0.5207 - accuracy: 0.7260 - precision_10: 0.8287 - val_loss: 8.6504 - val_accuracy: 0.6648 - val_precision_10: 0.4690\n",
      "Epoch 378/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5339 - accuracy: 0.7256 - precision_10: 0.8252 - val_loss: 21.4497 - val_accuracy: 0.6632 - val_precision_10: 0.4595\n",
      "Epoch 379/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5291 - accuracy: 0.7278 - precision_10: 0.8405 - val_loss: 17.9390 - val_accuracy: 0.6593 - val_precision_10: 0.4417\n",
      "Epoch 380/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5248 - accuracy: 0.7270 - precision_10: 0.8362 - val_loss: 14.8547 - val_accuracy: 0.6585 - val_precision_10: 0.4157\n",
      "Epoch 381/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5282 - accuracy: 0.7240 - precision_10: 0.8667 - val_loss: 4.7451 - val_accuracy: 0.6585 - val_precision_10: 0.4336\n",
      "Epoch 382/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5834 - accuracy: 0.7184 - precision_10: 0.8321 - val_loss: 3.7039 - val_accuracy: 0.6529 - val_precision_10: 0.3659\n",
      "Epoch 383/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5456 - accuracy: 0.7198 - precision_10: 0.8209 - val_loss: 3.4810 - val_accuracy: 0.6616 - val_precision_10: 0.4421\n",
      "Epoch 384/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5329 - accuracy: 0.7230 - precision_10: 0.8120 - val_loss: 9.0404 - val_accuracy: 0.6664 - val_precision_10: 0.4783\n",
      "Epoch 385/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5258 - accuracy: 0.7226 - precision_10: 0.8356 - val_loss: 7.0079 - val_accuracy: 0.6616 - val_precision_10: 0.4610\n",
      "Epoch 386/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5231 - accuracy: 0.7268 - precision_10: 0.8067 - val_loss: 10.4074 - val_accuracy: 0.6609 - val_precision_10: 0.4571\n",
      "Epoch 387/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6506 - accuracy: 0.7230 - precision_10: 0.8004 - val_loss: 1.3739 - val_accuracy: 0.6632 - val_precision_10: 0.4328\n",
      "Epoch 388/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5530 - accuracy: 0.7177 - precision_10: 0.8193 - val_loss: 5.1225 - val_accuracy: 0.6632 - val_precision_10: 0.4615\n",
      "Epoch 389/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.7415 - accuracy: 0.7214 - precision_10: 0.8114 - val_loss: 2.6836 - val_accuracy: 0.6585 - val_precision_10: 0.4359\n",
      "Epoch 390/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5299 - accuracy: 0.7226 - precision_10: 0.8237 - val_loss: 3.7382 - val_accuracy: 0.6632 - val_precision_10: 0.4536\n",
      "Epoch 391/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5537 - accuracy: 0.7206 - precision_10: 0.8084 - val_loss: 6.3336 - val_accuracy: 0.6585 - val_precision_10: 0.4336\n",
      "Epoch 392/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5307 - accuracy: 0.7256 - precision_10: 0.8322 - val_loss: 8.8361 - val_accuracy: 0.6601 - val_precision_10: 0.4425\n",
      "Epoch 393/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5172 - accuracy: 0.7299 - precision_10: 0.8238 - val_loss: 10.7377 - val_accuracy: 0.6601 - val_precision_10: 0.4270\n",
      "Epoch 394/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5298 - accuracy: 0.7264 - precision_10: 0.8552 - val_loss: 17.8636 - val_accuracy: 0.6624 - val_precision_10: 0.4490\n",
      "Epoch 395/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5203 - accuracy: 0.7313 - precision_10: 0.8436 - val_loss: 16.0350 - val_accuracy: 0.6569 - val_precision_10: 0.3976\n",
      "Epoch 396/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5456 - accuracy: 0.7272 - precision_10: 0.8533 - val_loss: 58.5218 - val_accuracy: 0.6506 - val_precision_10: 0.4138\n",
      "Epoch 397/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5363 - accuracy: 0.7236 - precision_10: 0.8375 - val_loss: 98.7480 - val_accuracy: 0.6632 - val_precision_10: 0.4536\n",
      "Epoch 398/500\n",
      "316/316 [==============================] - 7s 23ms/step - loss: 0.5156 - accuracy: 0.7305 - precision_10: 0.8466 - val_loss: 107.9650 - val_accuracy: 0.6648 - val_precision_10: 0.4701\n",
      "Epoch 399/500\n",
      "316/316 [==============================] - 7s 22ms/step - loss: 0.5322 - accuracy: 0.7186 - precision_10: 0.8013 - val_loss: 95.7110 - val_accuracy: 0.6601 - val_precision_10: 0.4435\n",
      "Epoch 400/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5181 - accuracy: 0.7276 - precision_10: 0.8107 - val_loss: 105.3364 - val_accuracy: 0.6609 - val_precision_10: 0.4444: 0.72 - ETA: 3s - loss:\n",
      "Epoch 401/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5140 - accuracy: 0.7272 - precision_10: 0.8455 - val_loss: 109.7218 - val_accuracy: 0.6688 - val_precision_10: 0.4917\n",
      "Epoch 402/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5175 - accuracy: 0.7289 - precision_10: 0.8397 - val_loss: 76.1756 - val_accuracy: 0.6616 - val_precision_10: 0.4225\n",
      "Epoch 403/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5190 - accuracy: 0.7240 - precision_10: 0.8544 - val_loss: 86.9873 - val_accuracy: 0.6585 - val_precision_10: 0.4272\n",
      "Epoch 404/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5264 - accuracy: 0.7282 - precision_10: 0.8219 - val_loss: 41.5963 - val_accuracy: 0.6553 - val_precision_10: 0.4021\n",
      "Epoch 405/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5600 - accuracy: 0.7161 - precision_10: 0.8270 - val_loss: 23.8338 - val_accuracy: 0.6632 - val_precision_10: 0.4628\n",
      "Epoch 406/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5302 - accuracy: 0.7145 - precision_10: 0.7390 - val_loss: 34.1401 - val_accuracy: 0.6585 - val_precision_10: 0.4528\n",
      "Epoch 407/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5220 - accuracy: 0.7216 - precision_10: 0.7549 - val_loss: 33.7730 - val_accuracy: 0.6498 - val_precision_10: 0.3774\n",
      "Epoch 408/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5195 - accuracy: 0.7274 - precision_10: 0.7794 - val_loss: 29.0205 - val_accuracy: 0.6569 - val_precision_10: 0.4274\n",
      "Epoch 409/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5255 - accuracy: 0.7258 - precision_10: 0.8326 - val_loss: 11.9032 - val_accuracy: 0.6490 - val_precision_10: 0.4118\n",
      "Epoch 410/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5179 - accuracy: 0.7266 - precision_10: 0.8243 - val_loss: 67.9000 - val_accuracy: 0.6601 - val_precision_10: 0.4301\n",
      "Epoch 411/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6893 - accuracy: 0.7240 - precision_10: 0.8194 - val_loss: 3.6119 - val_accuracy: 0.6593 - val_precision_10: 0.4327\n",
      "Epoch 412/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5553 - accuracy: 0.7287 - precision_10: 0.8351 - val_loss: 2.9745 - val_accuracy: 0.6648 - val_precision_10: 0.4624\n",
      "Epoch 413/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5313 - accuracy: 0.7244 - precision_10: 0.8390 - val_loss: 5.1581 - val_accuracy: 0.6537 - val_precision_10: 0.4266\n",
      "Epoch 414/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5189 - accuracy: 0.7258 - precision_10: 0.8370 - val_loss: 4.7308 - val_accuracy: 0.6498 - val_precision_10: 0.4167\n",
      "Epoch 415/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5182 - accuracy: 0.7276 - precision_10: 0.8373 - val_loss: 4.9740 - val_accuracy: 0.6521 - val_precision_10: 0.4196\n",
      "Epoch 416/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5098 - accuracy: 0.7307 - precision_10: 0.8264 - val_loss: 5.0419 - val_accuracy: 0.6553 - val_precision_10: 0.3908\n",
      "Epoch 417/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5236 - accuracy: 0.7315 - precision_10: 0.8833 - val_loss: 5.5231 - val_accuracy: 0.6664 - val_precision_10: 0.4757\n",
      "Epoch 418/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5094 - accuracy: 0.7323 - precision_10: 0.8383 - val_loss: 5.4861 - val_accuracy: 0.6569 - val_precision_10: 0.4320\n",
      "Epoch 419/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5145 - accuracy: 0.7321 - precision_10: 0.8435 - val_loss: 4.3607 - val_accuracy: 0.6482 - val_precision_10: 0.4239\n",
      "Epoch 420/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5186 - accuracy: 0.7303 - precision_10: 0.8098 - val_loss: 4.0619 - val_accuracy: 0.6585 - val_precision_10: 0.4299\n",
      "Epoch 421/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5177 - accuracy: 0.7278 - precision_10: 0.8224 - val_loss: 4.5997 - val_accuracy: 0.6545 - val_precision_10: 0.4231\n",
      "Epoch 422/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5173 - accuracy: 0.7297 - precision_10: 0.8300 - val_loss: 3.6012 - val_accuracy: 0.6609 - val_precision_10: 0.4423\n",
      "Epoch 423/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5320 - accuracy: 0.7262 - precision_10: 0.7770 - val_loss: 3.1415 - val_accuracy: 0.6680 - val_precision_10: 0.4854\n",
      "Epoch 424/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5177 - accuracy: 0.7319 - precision_10: 0.8562 - val_loss: 5.4478 - val_accuracy: 0.6561 - val_precision_10: 0.4416- accuracy: 0\n",
      "Epoch 425/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5212 - accuracy: 0.7260 - precision_10: 0.8232 - val_loss: 8.2713 - val_accuracy: 0.6545 - val_precision_10: 0.4123\n",
      "Epoch 426/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5164 - accuracy: 0.7284 - precision_10: 0.8330 - val_loss: 6.4873 - val_accuracy: 0.6529 - val_precision_10: 0.4035s - loss: 0.5186 - accuracy: 0.7283 - precision_10: 0 - ETA: 0s - loss: 0.5168 - accuracy: 0.7277 - precision_10: 0.83\n",
      "Epoch 427/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5203 - accuracy: 0.7274 - precision_10: 0.8054 - val_loss: 3.8783 - val_accuracy: 0.6537 - val_precision_10: 0.4364\n",
      "Epoch 428/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5383 - accuracy: 0.7224 - precision_10: 0.8121 - val_loss: 2.2601 - val_accuracy: 0.6482 - val_precision_10: 0.4205\n",
      "Epoch 429/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5195 - accuracy: 0.7297 - precision_10: 0.7596 - val_loss: 4.2784 - val_accuracy: 0.6529 - val_precision_10: 0.3962\n",
      "Epoch 430/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5143 - accuracy: 0.7315 - precision_10: 0.8178 - val_loss: 3.9111 - val_accuracy: 0.6537 - val_precision_10: 0.4276\n",
      "Epoch 431/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5776 - accuracy: 0.7301 - precision_10: 0.7918 - val_loss: 3.8963 - val_accuracy: 0.6458 - val_precision_10: 0.3798\n",
      "Epoch 432/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5284 - accuracy: 0.7286 - precision_10: 0.7837 - val_loss: 8.4160 - val_accuracy: 0.6513 - val_precision_10: 0.4032\n",
      "Epoch 433/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5533 - accuracy: 0.7280 - precision_10: 0.7908 - val_loss: 8.5249 - val_accuracy: 0.6545 - val_precision_10: 0.4390\n",
      "Epoch 434/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5151 - accuracy: 0.7327 - precision_10: 0.7986 - val_loss: 7.0879 - val_accuracy: 0.6545 - val_precision_10: 0.4351\n",
      "Epoch 435/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5546 - accuracy: 0.7305 - precision_10: 0.7957 - val_loss: 9.8332 - val_accuracy: 0.6529 - val_precision_10: 0.3804 loss: 0.5585 - accuracy: 0.7359 -\n",
      "Epoch 436/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5152 - accuracy: 0.7297 - precision_10: 0.8327 - val_loss: 13.4856 - val_accuracy: 0.6506 - val_precision_10: 0.4031\n",
      "Epoch 437/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5496 - accuracy: 0.7242 - precision_10: 0.8239 - val_loss: 2.6733 - val_accuracy: 0.6688 - val_precision_10: 0.4773\n",
      "Epoch 438/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5300 - accuracy: 0.7206 - precision_10: 0.7622 - val_loss: 7.1434 - val_accuracy: 0.6474 - val_precision_10: 0.4099\n",
      "Epoch 439/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5210 - accuracy: 0.7329 - precision_10: 0.8076 - val_loss: 5.2663 - val_accuracy: 0.6609 - val_precision_10: 0.4434\n",
      "Epoch 440/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5175 - accuracy: 0.7323 - precision_10: 0.8343 - val_loss: 4.8003 - val_accuracy: 0.6466 - val_precision_10: 0.3828\n",
      "Epoch 441/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5060 - accuracy: 0.7317 - precision_10: 0.8294 - val_loss: 6.6885 - val_accuracy: 0.6490 - val_precision_10: 0.3826\n",
      "Epoch 442/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5170 - accuracy: 0.7287 - precision_10: 0.8204 - val_loss: 5.9311 - val_accuracy: 0.6593 - val_precision_10: 0.4286\n",
      "Epoch 443/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5148 - accuracy: 0.7313 - precision_10: 0.8300 - val_loss: 3.8742 - val_accuracy: 0.6640 - val_precision_10: 0.4667\n",
      "Epoch 444/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5030 - accuracy: 0.7325 - precision_10: 0.7911 - val_loss: 5.5831 - val_accuracy: 0.6609 - val_precision_10: 0.4444\n",
      "Epoch 445/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5299 - accuracy: 0.7278 - precision_10: 0.8278 - val_loss: 1.7744 - val_accuracy: 0.6387 - val_precision_10: 0.3980\n",
      "Epoch 446/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5032 - accuracy: 0.7353 - precision_10: 0.7500 - val_loss: 2.3616 - val_accuracy: 0.6585 - val_precision_10: 0.4176\n",
      "Epoch 447/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5085 - accuracy: 0.7371 - precision_10: 0.8071 - val_loss: 2.9856 - val_accuracy: 0.6561 - val_precision_10: 0.4400\n",
      "Epoch 448/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5232 - accuracy: 0.7339 - precision_10: 0.8195 - val_loss: 4.4863 - val_accuracy: 0.6513 - val_precision_10: 0.4189\n",
      "Epoch 449/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5077 - accuracy: 0.7293 - precision_10: 0.8045 - val_loss: 4.4225 - val_accuracy: 0.6616 - val_precision_10: 0.4522\n",
      "Epoch 450/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5110 - accuracy: 0.7327 - precision_10: 0.8106 - val_loss: 1.7146 - val_accuracy: 0.6537 - val_precision_10: 0.3636\n",
      "Epoch 451/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5205 - accuracy: 0.7301 - precision_10: 0.7857 - val_loss: 3.7656 - val_accuracy: 0.6506 - val_precision_10: 0.4088\n",
      "Epoch 452/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5149 - accuracy: 0.7303 - precision_10: 0.8232 - val_loss: 5.1213 - val_accuracy: 0.6624 - val_precision_10: 0.4590\n",
      "Epoch 453/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5136 - accuracy: 0.7305 - precision_10: 0.8125 - val_loss: 5.6849 - val_accuracy: 0.6521 - val_precision_10: 0.4065\n",
      "Epoch 454/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5049 - accuracy: 0.7361 - precision_10: 0.7906 - val_loss: 4.8790 - val_accuracy: 0.6498 - val_precision_10: 0.4187\n",
      "Epoch 455/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5040 - accuracy: 0.7377 - precision_10: 0.8211 - val_loss: 6.8676 - val_accuracy: 0.6498 - val_precision_10: 0.4198\n",
      "Epoch 456/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5126 - accuracy: 0.7325 - precision_10: 0.7862 - val_loss: 6.4731 - val_accuracy: 0.6577 - val_precision_10: 0.4344\n",
      "Epoch 457/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5118 - accuracy: 0.7371 - precision_10: 0.8637 - val_loss: 9.6442 - val_accuracy: 0.6609 - val_precision_10: 0.4610\n",
      "Epoch 458/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5105 - accuracy: 0.7329 - precision_10: 0.8076 - val_loss: 11.4692 - val_accuracy: 0.6466 - val_precision_10: 0.4085\n",
      "Epoch 459/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.6228 - accuracy: 0.7287 - precision_10: 0.7653 - val_loss: 8.0409 - val_accuracy: 0.6616 - val_precision_10: 0.4495\n",
      "Epoch 460/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5156 - accuracy: 0.7321 - precision_10: 0.8177 - val_loss: 7.5309 - val_accuracy: 0.6466 - val_precision_10: 0.4324\n",
      "Epoch 461/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5062 - accuracy: 0.7373 - precision_10: 0.7955 - val_loss: 10.8482 - val_accuracy: 0.6474 - val_precision_10: 0.3957 0.5062 - accuracy: 0.7366\n",
      "Epoch 462/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5075 - accuracy: 0.7363 - precision_10: 0.7503 - val_loss: 9.5673 - val_accuracy: 0.6442 - val_precision_10: 0.3935\n",
      "Epoch 463/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5078 - accuracy: 0.7365 - precision_10: 0.7804 - val_loss: 7.3972 - val_accuracy: 0.6482 - val_precision_10: 0.4255\n",
      "Epoch 464/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5018 - accuracy: 0.7369 - precision_10: 0.7654 - val_loss: 13.4661 - val_accuracy: 0.6482 - val_precision_10: 0.3986\n",
      "Epoch 465/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5094 - accuracy: 0.7335 - precision_10: 0.7769 - val_loss: 10.9105 - val_accuracy: 0.6521 - val_precision_10: 0.4343\n",
      "Epoch 466/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5068 - accuracy: 0.7317 - precision_10: 0.7887 - val_loss: 15.5904 - val_accuracy: 0.6482 - val_precision_10: 0.4114\n",
      "Epoch 467/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5021 - accuracy: 0.7385 - precision_10: 0.7864 - val_loss: 15.6906 - val_accuracy: 0.6442 - val_precision_10: 0.3975\n",
      "Epoch 468/500\n",
      "316/316 [==============================] - 8s 24ms/step - loss: 0.5423 - accuracy: 0.7226 - precision_10: 0.7854 - val_loss: 7.7445 - val_accuracy: 0.6537 - val_precision_10: 0.4132\n",
      "Epoch 469/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5081 - accuracy: 0.7347 - precision_10: 0.8128 - val_loss: 6.6064 - val_accuracy: 0.6569 - val_precision_10: 0.4351\n",
      "Epoch 470/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5119 - accuracy: 0.7367 - precision_10: 0.8075 - val_loss: 5.8809 - val_accuracy: 0.6395 - val_precision_10: 0.4039\n",
      "Epoch 471/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5003 - accuracy: 0.7361 - precision_10: 0.7797 - val_loss: 17.3971 - val_accuracy: 0.6426 - val_precision_10: 0.4103\n",
      "Epoch 472/500\n",
      "316/316 [==============================] - 9s 27ms/step - loss: 0.5151 - accuracy: 0.7365 - precision_10: 0.7679 - val_loss: 3.4138 - val_accuracy: 0.6442 - val_precision_10: 0.4154\n",
      "Epoch 473/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5279 - accuracy: 0.7301 - precision_10: 0.7706 - val_loss: 9.7680 - val_accuracy: 0.6537 - val_precision_10: 0.4276\n",
      "Epoch 474/500\n",
      "316/316 [==============================] - 10s 32ms/step - loss: 0.5116 - accuracy: 0.7339 - precision_10: 0.7849 - val_loss: 14.7813 - val_accuracy: 0.6498 - val_precision_10: 0.4356\n",
      "Epoch 475/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5010 - accuracy: 0.7420 - precision_10: 0.7803 - val_loss: 16.4922 - val_accuracy: 0.6466 - val_precision_10: 0.4299\n",
      "Epoch 476/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.5207 - accuracy: 0.7341 - precision_10: 0.7816 - val_loss: 6.3420 - val_accuracy: 0.6506 - val_precision_10: 0.4372\n",
      "Epoch 477/500\n",
      "316/316 [==============================] - 11s 36ms/step - loss: 0.8122 - accuracy: 0.7200 - precision_10: 0.7658 - val_loss: 1.2885 - val_accuracy: 0.6704 - val_precision_10: 0.5000\n",
      "Epoch 478/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5851 - accuracy: 0.6887 - precision_10: 0.8083 - val_loss: 7.2710 - val_accuracy: 0.6601 - val_precision_10: 0.3673\n",
      "Epoch 479/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5642 - accuracy: 0.6978 - precision_10: 0.7741 - val_loss: 3.3408 - val_accuracy: 0.6561 - val_precision_10: 0.3636\n",
      "Epoch 480/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5427 - accuracy: 0.7129 - precision_10: 0.6739 - val_loss: 11.4622 - val_accuracy: 0.6458 - val_precision_10: 0.4292\n",
      "Epoch 481/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5244 - accuracy: 0.7276 - precision_10: 0.7347 - val_loss: 15.7204 - val_accuracy: 0.6347 - val_precision_10: 0.3934\n",
      "Epoch 482/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5054 - accuracy: 0.7351 - precision_10: 0.7428 - val_loss: 21.9856 - val_accuracy: 0.6434 - val_precision_10: 0.3963\n",
      "Epoch 483/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5073 - accuracy: 0.7339 - precision_10: 0.7274 - val_loss: 14.6709 - val_accuracy: 0.6450 - val_precision_10: 0.3824\n",
      "Epoch 484/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5029 - accuracy: 0.7373 - precision_10: 0.7486 - val_loss: 18.5057 - val_accuracy: 0.6387 - val_precision_10: 0.3969\n",
      "Epoch 485/500\n",
      "316/316 [==============================] - 9s 30ms/step - loss: 0.4989 - accuracy: 0.7402 - precision_10: 0.7727 - val_loss: 17.2464 - val_accuracy: 0.6363 - val_precision_10: 0.4061\n",
      "Epoch 486/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.5160 - accuracy: 0.7349 - precision_10: 0.7551 - val_loss: 21.8787 - val_accuracy: 0.6418 - val_precision_10: 0.4135\n",
      "Epoch 487/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5057 - accuracy: 0.7432 - precision_10: 0.7585 - val_loss: 19.3460 - val_accuracy: 0.6331 - val_precision_10: 0.3522\n",
      "Epoch 488/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5008 - accuracy: 0.7402 - precision_10: 0.7665 - val_loss: 11.9478 - val_accuracy: 0.6466 - val_precision_10: 0.4219\n",
      "Epoch 489/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.5024 - accuracy: 0.7351 - precision_10: 0.7231 - val_loss: 19.4482 - val_accuracy: 0.6387 - val_precision_10: 0.4065\n",
      "Epoch 490/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.4979 - accuracy: 0.7434 - precision_10: 0.7637 - val_loss: 11.6854 - val_accuracy: 0.6395 - val_precision_10: 0.4235\n",
      "Epoch 491/500\n",
      "316/316 [==============================] - 8s 27ms/step - loss: 0.4965 - accuracy: 0.7396 - precision_10: 0.7327 - val_loss: 17.5674 - val_accuracy: 0.6426 - val_precision_10: 0.3704\n",
      "Epoch 492/500\n",
      "316/316 [==============================] - 8s 26ms/step - loss: 0.4952 - accuracy: 0.7432 - precision_10: 0.7532 - val_loss: 19.2308 - val_accuracy: 0.6458 - val_precision_10: 0.4378\n",
      "Epoch 493/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.5088 - accuracy: 0.7408 - precision_10: 0.7560 - val_loss: 13.0144 - val_accuracy: 0.6458 - val_precision_10: 0.4351\n",
      "Epoch 494/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5024 - accuracy: 0.7377 - precision_10: 0.7660 - val_loss: 16.7204 - val_accuracy: 0.6545 - val_precision_10: 0.4550\n",
      "Epoch 495/500\n",
      "316/316 [==============================] - 10s 30ms/step - loss: 0.4956 - accuracy: 0.7400 - precision_10: 0.7708 - val_loss: 24.3745 - val_accuracy: 0.6506 - val_precision_10: 0.4365\n",
      "Epoch 496/500\n",
      "316/316 [==============================] - 9s 28ms/step - loss: 0.4985 - accuracy: 0.7424 - precision_10: 0.7955 - val_loss: 13.4542 - val_accuracy: 0.6434 - val_precision_10: 0.3819on_10: - ETA: 1s - loss: 0.4895 - accuracy: 0.\n",
      "Epoch 497/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5021 - accuracy: 0.7418 - precision_10: 0.8076 - val_loss: 32.5714 - val_accuracy: 0.6387 - val_precision_10: 0.4107\n",
      "Epoch 498/500\n",
      "316/316 [==============================] - 8s 25ms/step - loss: 0.5119 - accuracy: 0.7402 - precision_10: 0.7947 - val_loss: 9.9039 - val_accuracy: 0.6458 - val_precision_10: 0.4229\n",
      "Epoch 499/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.5079 - accuracy: 0.7311 - precision_10: 0.7699 - val_loss: 10.5098 - val_accuracy: 0.6490 - val_precision_10: 0.4129\n",
      "Epoch 500/500\n",
      "316/316 [==============================] - 9s 29ms/step - loss: 0.4989 - accuracy: 0.7430 - precision_10: 0.8206 - val_loss: 17.2277 - val_accuracy: 0.6410 - val_precision_10: 0.4031\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train,y_train, batch_size = 16,validation_split= 0.2, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d25d04cb-aafb-4cbb-8dac-17a33ca81803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9e7a749b-7f3d-4031-ab0b-655f418644da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8a155f4-3a1e-4a4a-9970-7068103a005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/step - loss: 15.5798 - accuracy: 0.6483 - precision_10: 0.4675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.579841613769531, 0.6482889652252197, 0.4675324559211731]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "93d63633-bfa1-463a-9b6d-635e6cb9ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ffb26932-60cb-4d25-94f1-d69c2132aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d9816d8a-df06-4b6d-8b81-d2cb7d850d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred>0.9,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "46f5af66-7cff-4738-bbc5-9cb7dae6e870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 44, 496],\n",
       "       [ 47, 991]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred,labels = [1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13e37e-70c2-441f-aae7-f39754a64464",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
